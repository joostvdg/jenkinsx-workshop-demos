{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Jenkins X Demos Hi.","title":"Home"},{"location":"#jenkins-x-demos","text":"Hi.","title":"Jenkins X Demos"},{"location":"go-demo/","text":"Go Demo This is a minimal HelloWorld demo! First, make sure you have a Kubernetes cluster with Jenkins X installe Warning It is easiest to use all the default values, such as a dns on nip.io and Static Jenkins . Create Quickstart Let's examine what quickstart does. 1 jx create quickstart # Cancel with ctrl+c Cancel it with ctr+c , as it will be very interactive. Let's create the Go (lang) demo! 1 jx create quickstart -l go -p jx-go -b Info Go to github.com/jenkins-x-quickstarts to see all the available quickstarts. Open repo Replace ? with your GitHub user. 1 export GH_USER = ? 1 open https://github.com/ $GH_USER /jx-go View created files Let's take a look at what was created: 1 ls -l jx-go Dockerfile 1 cat jx-go/Dockerfile pipeline 1 cat jx-go/jenkins-x.yml Makefile 1 cat jx-go/Makefile Skaffold 1 cat jx-go/skaffold.yaml And let's take a loot at the Helm charts. Charts root 1 ls -l jx-go/charts Application Chart 1 ls -l jx-go/charts/jx-go Preview Chart 1 ls -l jx-go/charts/preview Webhook Jenkins X works with Git and wants to work event based. This means there should be a webhook, which will be send to our Jenkins X's cluster. 1 open https://github.com/ $GH_USER /jx-go/settings/hooks Releases Jenkins X will create releases for you in your Git repository (where applicable). To view them: 1 open https://github.com/ $GH_USER /jx-go/releases Explore Application in JX Jenkins UI 1 jx console Activities 1 jx get activities Acitivites jx-go 1 jx get activities -f jx-go -w # Cancel with ctrl+c Build Logs 1 jx get build logs # Cancel with ctrl+c Build Logs jx-go 1 jx get build logs -f jx-go # Cancel with ctrl+c Build Logs of Job 1 jx get build logs $GH_USER /jx-go/master General Jenkins X listings Pipelines 1 jx get pipelines Applications 1 jx get applications Applications in Env 1 jx get applications -e staging Environments 1 jx get env Update the application First, make sure the application has been build successfully and is running in our staging environment. Confirm we're ready 1 jx get activities -f jx-go -w You should see something like, after which we can continue the next step. 1 2 3 4 5 6 7 STEP STARTED AGO DURATION STATUS joostvdg/jx-go/master #1 Running Version: 0.0.1 Release 4m23s 1m0s Succeeded Promote: staging 3m23s 2m26s Succeeded PullRequest 3m23s 1m25s Succeeded PullRequest: https://github.com/joostvdg/environment-jx-staging/pull/1 Merge SHA: f602fd78694fcfef7b59b27469e0e2b8538e1bb7 Update 1m58s 1m1s Succeeded Status: Success at: http://jenkins.jx.35.231.11.119.nip.io/job/joostvdg/job/environment-jx-staging/job/master/2/display/redirect Promoted 1m58s 1m1s Succeeded Application is at: http://jx-go.jx-staging.35.231.11.119.nip.io 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-go -o jsonpath = {.spec.rules[0].host} ) open http:// $APP_ADDR You should see a very fancy (for 1992) page which says Hello from: Jenkins X golang http example . Make the change We will now create a WIP branch. 1 git checkout -b wip Now edit our main.go file using your favorite editor - or VIM if you want. Change the title variable: title := Jenkins X golang http example to a value you like. For example: title := Jenkins X Is Awesome! . 1 2 3 git add main.go git commit -m changed our message to be awesome git push origin wip Create PR We will have to create PR for our change. When pushing to Git, you should have received a link to create a pr. If not, see below: 1 open https://github.com/ ${ GH_USER } /jx-go/pull/new/wip Keep the PR page open, you will see why! We will watch the activities to see when our preview is ready! 1 jx get activities -f jx-go -w Once we see something like Preview Application 0s http://jx-go.jx-joostvdg-jx-go-pr-1.35.231.11.119.nip.io We can go back to our PR page, which should now the link to the preview as well! Confirm your change is successful and merge the pull request by clicking the merge button. Go back to the activities feed - in case you closed it. And wait for the PR to land in staging. 1 jx get activities -f jx-go -w Once the activity Promote: staging is succeeded, we can confirm our application is updated. 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-go -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR To wrap up, go back to the master branch and pull the changes from the PR. 1 2 git checkout master git pull Promote to Production Applications will be automatically promoted to staging, to promote them to production we have to take manual action. How do you promote manually To manually Promote a version of your application to an environment use the jx promote command. 1 jx promote --app myapp --version 1 .2.3 --env production The command waits for the promotion to complete, logging details of its progress. You can specify the timeout to wait for the promotion to complete via the --timeout argument. e.g. to wait for 5 hours 1 jx promote --app myapp --version 1 .2.3 --env production --timeout 5h You can use terms like 20m or 10h30m for the various duration expressions. To promote our jx-go application, run the following command. Promote jx-go to production 1 jx promote --app jx-go --version 0 .0.1 --env production --timeout 1h Info You will get a warning message stating Failed to query the Pull Request last commit status for , which is at this time (April 2019) expected behavior. Once the promotion is completed successfully, you should be returned to your console. Let's confirm our application landed in Production! 1 2 APP_ADDR = $( kubectl get ing -n jx-production jx-go -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR","title":"Quickstart Demo"},{"location":"go-demo/#go-demo","text":"This is a minimal HelloWorld demo! First, make sure you have a Kubernetes cluster with Jenkins X installe Warning It is easiest to use all the default values, such as a dns on nip.io and Static Jenkins .","title":"Go Demo"},{"location":"go-demo/#create-quickstart","text":"Let's examine what quickstart does. 1 jx create quickstart # Cancel with ctrl+c Cancel it with ctr+c , as it will be very interactive. Let's create the Go (lang) demo! 1 jx create quickstart -l go -p jx-go -b Info Go to github.com/jenkins-x-quickstarts to see all the available quickstarts.","title":"Create Quickstart"},{"location":"go-demo/#open-repo","text":"Replace ? with your GitHub user. 1 export GH_USER = ? 1 open https://github.com/ $GH_USER /jx-go","title":"Open repo"},{"location":"go-demo/#view-created-files","text":"Let's take a look at what was created: 1 ls -l jx-go Dockerfile 1 cat jx-go/Dockerfile pipeline 1 cat jx-go/jenkins-x.yml Makefile 1 cat jx-go/Makefile Skaffold 1 cat jx-go/skaffold.yaml And let's take a loot at the Helm charts. Charts root 1 ls -l jx-go/charts Application Chart 1 ls -l jx-go/charts/jx-go Preview Chart 1 ls -l jx-go/charts/preview","title":"View created files"},{"location":"go-demo/#webhook","text":"Jenkins X works with Git and wants to work event based. This means there should be a webhook, which will be send to our Jenkins X's cluster. 1 open https://github.com/ $GH_USER /jx-go/settings/hooks","title":"Webhook"},{"location":"go-demo/#releases","text":"Jenkins X will create releases for you in your Git repository (where applicable). To view them: 1 open https://github.com/ $GH_USER /jx-go/releases","title":"Releases"},{"location":"go-demo/#explore-application-in-jx","text":"Jenkins UI 1 jx console Activities 1 jx get activities Acitivites jx-go 1 jx get activities -f jx-go -w # Cancel with ctrl+c Build Logs 1 jx get build logs # Cancel with ctrl+c Build Logs jx-go 1 jx get build logs -f jx-go # Cancel with ctrl+c Build Logs of Job 1 jx get build logs $GH_USER /jx-go/master","title":"Explore Application in JX"},{"location":"go-demo/#general-jenkins-x-listings","text":"Pipelines 1 jx get pipelines Applications 1 jx get applications Applications in Env 1 jx get applications -e staging Environments 1 jx get env","title":"General Jenkins X listings"},{"location":"go-demo/#update-the-application","text":"First, make sure the application has been build successfully and is running in our staging environment.","title":"Update the application"},{"location":"go-demo/#confirm-were-ready","text":"1 jx get activities -f jx-go -w You should see something like, after which we can continue the next step. 1 2 3 4 5 6 7 STEP STARTED AGO DURATION STATUS joostvdg/jx-go/master #1 Running Version: 0.0.1 Release 4m23s 1m0s Succeeded Promote: staging 3m23s 2m26s Succeeded PullRequest 3m23s 1m25s Succeeded PullRequest: https://github.com/joostvdg/environment-jx-staging/pull/1 Merge SHA: f602fd78694fcfef7b59b27469e0e2b8538e1bb7 Update 1m58s 1m1s Succeeded Status: Success at: http://jenkins.jx.35.231.11.119.nip.io/job/joostvdg/job/environment-jx-staging/job/master/2/display/redirect Promoted 1m58s 1m1s Succeeded Application is at: http://jx-go.jx-staging.35.231.11.119.nip.io 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-go -o jsonpath = {.spec.rules[0].host} ) open http:// $APP_ADDR You should see a very fancy (for 1992) page which says Hello from: Jenkins X golang http example .","title":"Confirm we're ready"},{"location":"go-demo/#make-the-change","text":"We will now create a WIP branch. 1 git checkout -b wip Now edit our main.go file using your favorite editor - or VIM if you want. Change the title variable: title := Jenkins X golang http example to a value you like. For example: title := Jenkins X Is Awesome! . 1 2 3 git add main.go git commit -m changed our message to be awesome git push origin wip","title":"Make the change"},{"location":"go-demo/#create-pr","text":"We will have to create PR for our change. When pushing to Git, you should have received a link to create a pr. If not, see below: 1 open https://github.com/ ${ GH_USER } /jx-go/pull/new/wip Keep the PR page open, you will see why! We will watch the activities to see when our preview is ready! 1 jx get activities -f jx-go -w Once we see something like Preview Application 0s http://jx-go.jx-joostvdg-jx-go-pr-1.35.231.11.119.nip.io We can go back to our PR page, which should now the link to the preview as well! Confirm your change is successful and merge the pull request by clicking the merge button. Go back to the activities feed - in case you closed it. And wait for the PR to land in staging. 1 jx get activities -f jx-go -w Once the activity Promote: staging is succeeded, we can confirm our application is updated. 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-go -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR To wrap up, go back to the master branch and pull the changes from the PR. 1 2 git checkout master git pull","title":"Create PR"},{"location":"go-demo/#promote-to-production","text":"Applications will be automatically promoted to staging, to promote them to production we have to take manual action.","title":"Promote to Production"},{"location":"go-demo/#how-do-you-promote-manually","text":"To manually Promote a version of your application to an environment use the jx promote command. 1 jx promote --app myapp --version 1 .2.3 --env production The command waits for the promotion to complete, logging details of its progress. You can specify the timeout to wait for the promotion to complete via the --timeout argument. e.g. to wait for 5 hours 1 jx promote --app myapp --version 1 .2.3 --env production --timeout 5h You can use terms like 20m or 10h30m for the various duration expressions. To promote our jx-go application, run the following command.","title":"How do you promote manually"},{"location":"go-demo/#promote-jx-go-to-production","text":"1 jx promote --app jx-go --version 0 .0.1 --env production --timeout 1h Info You will get a warning message stating Failed to query the Pull Request last commit status for , which is at this time (April 2019) expected behavior. Once the promotion is completed successfully, you should be returned to your console. Let's confirm our application landed in Production! 1 2 APP_ADDR = $( kubectl get ing -n jx-production jx-go -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR","title":"Promote jx-go to production"},{"location":"install/","text":"Install Jenkins X Install Prerequisites Git GitBash if Windows Kubectl Helm Public cloud CLI such as gcloud Info For Windows, we recommend using the Chocolatey package manager. Info For Linux, we recommend using the Snap package manager. Info For MacOS we recommend using the Homebrew package manager. Git Debian 1 2 3 sudo apt-get update sudo apt-get upgrade sudo apt-get install git RHEL 1 2 sudo yum upgrade sudo yum install git Homebrew 1 brew install git Windows 1 2 choco install git.install choco install hub Kubectl Snap 1 2 sudo snap install kubectl --classic kubectl version Debian 1 2 3 4 5 sudo apt-get update sudo apt-get install -y apt-transport-https curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - echo deb https://apt.kubernetes.io/ kubernetes-xenial main | sudo tee -a /etc/apt/sources.list.d/kubernetes.list sudo apt-get update sudo apt-get install -y kubectl RHEL 1 2 3 4 5 6 7 8 9 10 cat EOF /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF yum install -y kubectl Homebrew 1 brew install kubernetes-cli Windows 1 choco install kubernetes-cli Curl 1 2 3 curl -LO https://storage.googleapis.com/kubernetes-release/release/ $( curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt ) /bin/linux/amd64/kubectl chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl Helm Snap 1 sudo snap install helm --classic Homebrew 1 brew install kubernetes-helm Windows 1 choco install kubernetes-helm For other options, visit the install guide . Cloud CLI's AWS Snap 1 sudo snap install aws-cli --classic Homebrew 1 brew install awscli Windows 1 choco install awscli For other options, visit the install guide . EKS CTL Linux 1 2 curl --silent --location https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_ $( uname -s ) _amd64.tar.gz | tar xz -C /tmp sudo mv /tmp/eksctl /usr/local/bin Homebrew 1 2 brew tap weaveworks/tap brew install weaveworks/tap/eksctl Windows 1 chocolatey install eksctl For other options, visit the install guide . Google Snap 1 sudo snap install google-cloud-sdk --classic Homebrew 1 brew cask install google-cloud-sdk. Windows 1 choco install gcloudsdk For other options, visit the install guide . Azure Snap 1 sudo snap install aws-cli --classic Homebrew 1 brew install awscli Windows 1 choco install azure-cli For other options, visit the install guide . Install JX Binary The jx binary is the main vehicle for Jenkins X to manage anything related to Jenkins X and your applications. Warning It is recommended to always update your jx binary at the start of your workday. It gets updates and fixes several times a day, so don't stay behind! Info If you are running on Mac OS X, Jenkins X is using Homebrew to install the various CLI. It will install it if not present. Install Linux 1 2 3 4 mkdir -p ~/.jx/bin curl -L https://github.com/jenkins-x/jx/releases/download/v1.3.1068/jx-linux-amd64.tar.gz | tar xzv -C ~/.jx/bin export PATH = $PATH :~/.jx/bin echo export PATH=$PATH:~/.jx/bin ~/.bashrc RHEL 1 2 sudo yum upgrade sudo yum install git Homebrew 1 2 brew tap jenkins-x/jx brew install jx Windows 1 choco install jenkins-x Install JX w/ Cluster You can install Jenkins X in an existing Kubernetes cluster, or let it install a cluster for you. Below are the examples for installing a cluster via Jenkins X before it installs itself into it. Info For all the installation options, please consult the jx CLI. jx create cluster ${clusterType} --help When in doubt, accept the default value! Variables Set these variables in your console, for use with the install commands. CLUSTER_NAME your desired cluster name (can be anything) PROJECT is your Google Cloud project-id you can retrieve this via your console or via the gcloud CLI: gcloud config list 1 2 3 4 5 6 7 REGION = us-east1 ZONE = ${ REGION } -b PREFIX = jx MACHINE_TYPE = n1-standard-2 ADMIN_PSW = admin CLUSTER_NAME = PROJECT = Configuration Warning If you are using Java with Maven or Gradle, you'd want to install Nexus. Else, you can disable it as per example below. Disable Nexus Copy below text into a file called myvalues.yaml . 1 2 nexus: enabled: false Install Info EKS option will download and use the eksctl tool to create a new EKS cluster, then it\u2019ll install Jenkins X on top. Info When you're creating your first cluster with GKE, you will need to login for authorization. If you have authorization taken care of, you can add --no-login to prevent the process. GKE 1 2 3 4 jx create cluster gke -n $CLUSTER_NAME -p $PROJECT -z ${ ZONE } \\ -m ${ MACHINE_TYPE } --min-num-nodes 3 --max-num-nodes 5 \\ --default-admin-password = ${ ADMIN_PSW } \\ --default-environment-prefix ${ PREFIX } --no-tiller EKS 1 jx create cluster eks Kops 1 jx create cluster aws Azure 1 jx create cluster aks For more options and information, read the documentation . Test install 1 kubectl -n jx get pods Install Serverless Variables 1 2 3 4 5 6 7 CLUSTER_NAME = PROJECT = ADMIN_PSW = admin PREFIX = jx REGION = us-east1 ZONE = ${ REGION } -a MACHINE_TYPE = n1-standard-1 Install GKE 1 2 3 4 5 jx create cluster gke -n $CLUSTER_NAME -p $PROJECT -z ${ ZONE } \\ -m n1-standard-2 --min-num-nodes 3 --max-num-nodes 5 \\ --default-admin-password = ${ ADMIN_PSW } \\ --default-environment-prefix \\ --prow --tekton --no-tiller","title":"Install"},{"location":"install/#install-jenkins-x","text":"","title":"Install Jenkins X"},{"location":"install/#install-prerequisites","text":"Git GitBash if Windows Kubectl Helm Public cloud CLI such as gcloud Info For Windows, we recommend using the Chocolatey package manager. Info For Linux, we recommend using the Snap package manager. Info For MacOS we recommend using the Homebrew package manager.","title":"Install Prerequisites"},{"location":"install/#git","text":"Debian 1 2 3 sudo apt-get update sudo apt-get upgrade sudo apt-get install git RHEL 1 2 sudo yum upgrade sudo yum install git Homebrew 1 brew install git Windows 1 2 choco install git.install choco install hub","title":"Git"},{"location":"install/#kubectl","text":"Snap 1 2 sudo snap install kubectl --classic kubectl version Debian 1 2 3 4 5 sudo apt-get update sudo apt-get install -y apt-transport-https curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - echo deb https://apt.kubernetes.io/ kubernetes-xenial main | sudo tee -a /etc/apt/sources.list.d/kubernetes.list sudo apt-get update sudo apt-get install -y kubectl RHEL 1 2 3 4 5 6 7 8 9 10 cat EOF /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF yum install -y kubectl Homebrew 1 brew install kubernetes-cli Windows 1 choco install kubernetes-cli Curl 1 2 3 curl -LO https://storage.googleapis.com/kubernetes-release/release/ $( curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt ) /bin/linux/amd64/kubectl chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl","title":"Kubectl"},{"location":"install/#helm","text":"Snap 1 sudo snap install helm --classic Homebrew 1 brew install kubernetes-helm Windows 1 choco install kubernetes-helm For other options, visit the install guide .","title":"Helm"},{"location":"install/#cloud-clis","text":"","title":"Cloud CLI's"},{"location":"install/#aws","text":"Snap 1 sudo snap install aws-cli --classic Homebrew 1 brew install awscli Windows 1 choco install awscli For other options, visit the install guide .","title":"AWS"},{"location":"install/#eks-ctl","text":"Linux 1 2 curl --silent --location https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_ $( uname -s ) _amd64.tar.gz | tar xz -C /tmp sudo mv /tmp/eksctl /usr/local/bin Homebrew 1 2 brew tap weaveworks/tap brew install weaveworks/tap/eksctl Windows 1 chocolatey install eksctl For other options, visit the install guide .","title":"EKS CTL"},{"location":"install/#google","text":"Snap 1 sudo snap install google-cloud-sdk --classic Homebrew 1 brew cask install google-cloud-sdk. Windows 1 choco install gcloudsdk For other options, visit the install guide .","title":"Google"},{"location":"install/#azure","text":"Snap 1 sudo snap install aws-cli --classic Homebrew 1 brew install awscli Windows 1 choco install azure-cli For other options, visit the install guide .","title":"Azure"},{"location":"install/#install-jx-binary","text":"The jx binary is the main vehicle for Jenkins X to manage anything related to Jenkins X and your applications. Warning It is recommended to always update your jx binary at the start of your workday. It gets updates and fixes several times a day, so don't stay behind! Info If you are running on Mac OS X, Jenkins X is using Homebrew to install the various CLI. It will install it if not present.","title":"Install JX Binary"},{"location":"install/#install","text":"Linux 1 2 3 4 mkdir -p ~/.jx/bin curl -L https://github.com/jenkins-x/jx/releases/download/v1.3.1068/jx-linux-amd64.tar.gz | tar xzv -C ~/.jx/bin export PATH = $PATH :~/.jx/bin echo export PATH=$PATH:~/.jx/bin ~/.bashrc RHEL 1 2 sudo yum upgrade sudo yum install git Homebrew 1 2 brew tap jenkins-x/jx brew install jx Windows 1 choco install jenkins-x","title":"Install"},{"location":"install/#install-jx-w-cluster","text":"You can install Jenkins X in an existing Kubernetes cluster, or let it install a cluster for you. Below are the examples for installing a cluster via Jenkins X before it installs itself into it. Info For all the installation options, please consult the jx CLI. jx create cluster ${clusterType} --help When in doubt, accept the default value!","title":"Install JX w/ Cluster"},{"location":"install/#variables","text":"Set these variables in your console, for use with the install commands. CLUSTER_NAME your desired cluster name (can be anything) PROJECT is your Google Cloud project-id you can retrieve this via your console or via the gcloud CLI: gcloud config list 1 2 3 4 5 6 7 REGION = us-east1 ZONE = ${ REGION } -b PREFIX = jx MACHINE_TYPE = n1-standard-2 ADMIN_PSW = admin CLUSTER_NAME = PROJECT =","title":"Variables"},{"location":"install/#configuration","text":"Warning If you are using Java with Maven or Gradle, you'd want to install Nexus. Else, you can disable it as per example below.","title":"Configuration"},{"location":"install/#disable-nexus","text":"Copy below text into a file called myvalues.yaml . 1 2 nexus: enabled: false","title":"Disable Nexus"},{"location":"install/#install_1","text":"Info EKS option will download and use the eksctl tool to create a new EKS cluster, then it\u2019ll install Jenkins X on top. Info When you're creating your first cluster with GKE, you will need to login for authorization. If you have authorization taken care of, you can add --no-login to prevent the process. GKE 1 2 3 4 jx create cluster gke -n $CLUSTER_NAME -p $PROJECT -z ${ ZONE } \\ -m ${ MACHINE_TYPE } --min-num-nodes 3 --max-num-nodes 5 \\ --default-admin-password = ${ ADMIN_PSW } \\ --default-environment-prefix ${ PREFIX } --no-tiller EKS 1 jx create cluster eks Kops 1 jx create cluster aws Azure 1 jx create cluster aks For more options and information, read the documentation .","title":"Install"},{"location":"install/#test-install","text":"1 kubectl -n jx get pods","title":"Test install"},{"location":"install/#install-serverless","text":"","title":"Install Serverless"},{"location":"install/#variables_1","text":"1 2 3 4 5 6 7 CLUSTER_NAME = PROJECT = ADMIN_PSW = admin PREFIX = jx REGION = us-east1 ZONE = ${ REGION } -a MACHINE_TYPE = n1-standard-1","title":"Variables"},{"location":"install/#install_2","text":"GKE 1 2 3 4 5 jx create cluster gke -n $CLUSTER_NAME -p $PROJECT -z ${ ZONE } \\ -m n1-standard-2 --min-num-nodes 3 --max-num-nodes 5 \\ --default-admin-password = ${ ADMIN_PSW } \\ --default-environment-prefix \\ --prow --tekton --no-tiller","title":"Install"},{"location":"to-be-processed/","text":"Jenkins X Introduction Notes from Slack Tips Tricks https://github.com/jenkinsci/kubernetes-credentials-provider-plugin volume storage with Heptio's Valerio debugging: https://jenkins-x.io/contribute/development/#debugging --gitops mode have to check this jx upgrade platform knative authentication --git-username --org are complimentary, --organisations is unrelated username = the user for the repo's (apps env) org = the organization for the repo's (apps env) e.g.: --git-username joostvdg --org demomon --organisations is used to query GitHub for Quickstarts (no need to specify unless you have alternatives) Jenkins configurations do not persist you can specify them in a ConfigMap though https://github.com/jenkins-x/charts/blob/jenkins/stable/jenkins/templates/config.yaml#L8 credentials used for config can be found here: ~/.jx/jenkinsAuth.yam PodTemplates (static Jenkins) are from the Jenkins Kubernetes Plugin cleanup GKE jx gc gke you can create separate teams with --no-tiller even if the installation was done with Tiller jx init to \"fix\" a outdated ~/.jx folder https://jenkins-x.io/commands/jx_step_credential/ don't do mono repo's why? - https://medium.com/@mattklein123/monorepos-please-dont-e9a279be011b but if you do, https://fuchsia.googlesource.com/jiri/ using a different git provider --git-provider-url .... --git-provider-kind bitbucketserver --git-username foo --git-api-token whatever https://jenkins-x.io/developing/git/#using-a-different-git-provider-for-environments jx start pipeline to manually trigger a pipeline (I assume static Jenkins only) enable GCS for chartmuseum backend https://github.com/jenkins-x/cloud-environments/blob/master/env-jx-infra/myvalues.yaml#L10-L17 jx wraps kubectx tool, so you can use jx ns namespace to change your context to a different namespace faq for diagnosing exposecontroller issues: https://jenkins-x.io/faq/issues/#how-can-i-diagnose-exposecontroller-issues controller is used to generate ingress resources https://github.com/lvlstudio/jenkins-x-builders/tree/master/builder-nodejs-mysql https://github.com/jenkins-x/jx/issues/2550 https://github.com/jenkins-x/jenkins-x-platform/issues/4768 Tillerless: https://jenkins-x.io/news/helm-without-tiller/ difference between jx create quickstart and selecting spring vs. jx create spring jx create spring is an interactive wizard that uses the spring initialiser https://start.spring.io/ jx create quickstart uses a configurable github org to list available existing quickstarts i.e. https://github.com/jenkins-x-quickstarts (edited) multi-cluster support: https://github.com/jenkins-x-charts/environment-controller https://github.com/jenkins-x/jx/issues/479 jx create user ? https://jenkins-x.io/commands/jx_create_jenkins_token/ for problems with wild card certificates doing only one segment (i.e., *.example.com instead of *.*.example.com ) no - we can tweak that. It\u2019s easiest with wildcard - then any exposed service at svc.ns.domain just works - but you could register each namespace in DNS we\u2019ve not exposed that property to the jx install CLI yet - but you could try kubectl edit cm ingress-config urltemplate: {{.Service}}-{{.Namespace}}.{{.Domain}} and then jx upgrade ingress doesn't seem to work yet? (customization gets reverted) alternative, add dns entries to the ingress resources https://jenkins-x.io/getting-started/install-on-cluster/#installing-jenkins-x-on-premise Helm tips tricks for changing secrets https://github.com/helm/helm/blob/master/docs/charts_tips_and_tricks.md#user-content-automatically-roll-deployments-when-configmaps-or-secrets-change how to run integration tests I've answered this in a previous thread. Basically you use the helm chart (which includes the service dependencies as requirements). You create a preview but set the replicaCount for your service to 0 (that way, just the requirements are started). Then just run your tests against the requirements and delete the preview afterwards. Search the channel history for my messages and replicaCount. You should find it. https://jenkins-x.io/faq/develop/#how-do-i-add-other-services-into-a-preview managing static jenkins config has some issues https://github.com/jenkins-x/jx/issues/2991 https://github.com/jenkins-x/jx-docs/issues/1039 https://github.com/helm/charts/pull/9296/files we\u2019re super close from recommending folks use jx create cluster ... --vault --gitops which uses a git repository to store all the configuration changes + versions of stuff - and uses Vault to store all secrets we just merged the last few fixes so it should work for static jenkins servers with the latest jx binary - feb 7 Info It is Ready: jx create cluster gke --vault --gitops --no-tiller Multiple Micro-services if 1 microservice was 1 helm chart with a few different containers for example; you may have a few repos that just make binaries/docker images - then 1 repo which contains the helm chart of the microservice - you can also easily combine microservices together into an uber helm chart - James Strachan we prefer to use multiple repositories so that things are more microservice based. The problem with monorepos is everything gets released on every change; with separate repos its easier to manage change etc to handle changing versions of things across repositories we use updatebot ourselves to do \u2018CI/CD of dependencies\u2019 - we kinda think of it as promotion of dependencies like we promote microservices into environments - its PRs generated as part of the release process the main decision to make really is, , if you have, say, 3 microservices that are fairly tightly coupled; do you combine 3 versions of them all into 1 chart and then release that 1 chart when its all tested together; or do you release the 3 things totally independently - it depeends on coupling and team structure really you can switch from one to the other at any time really https://github.com/jenkins-x/updatebot 1 2 3 4 5 6 7 8 9 10 11 12 # Setup: $ jx create cluster gke -n team1 --default-environment-prefix team1 $ jx create quickstart -p app1 $ jx create quickstart -p app2 $ jx create quickstart -p app3 # The 5 repos: environment-team1-staging environment-team1-production app1 app2 app3 Practices Principles Principles Faster time to market Improved deployment frequency Shorter time between fixes Lower failure rate of releases Faster Mean Time To Recovery Practices Loosely-coupled Architectures Self-service Configuration Automated Provisioning Continuous Build / Integration and Delivery Automated Release Management Incremental Testing Infrastructure Configuration as Code Comprehensive configuration management Trunk based development and feature flags Prerequisites Primary jx Git Docker Kubernetes Helm Secondary Nexus GitOps Skaffold KNative Prow KSync JX Git Docker Kubernetes any public cloud will do GKE is recommended Validate Cluster for Jenkins X Compliance You can read this article from Viktor Farcic on how to confirm if your cluster is compliant with Jenkins X's requirements. Jenkins X has a binary, called jx , which includes some facilities from the Sonobuoy SDK to provide some validation capabilities. Run compliance check To run the compliance check, just use the jx command below. 1 jx compliance run Warning The compliance check will run for about one hour! Check Compliance run status 1 jx compliance status Check Compliance run logs 1 jx compliance logs -f See Compliance run results 1 jx compliance results Cleanup Once you're done with the compliance run, you can clean up any resources it created for the run. 1 jx compliance delete Helm package manager for Kubernetes quivalent to yum install package Kubernetes manifest template (Go templates), packaged and versioned, reffered to as Charts Use Cases manages packages, repositories and installations manage dependencies to other Charts meaning: you can create bundles allows for customizing standardized installations on Kubernetes for example: MySQL database with specific database, users and settings used as building blocks in other tools separate packaging (Chart) from runtime (application image) there's the chart version and the application version Architecture Helm repository = a hosted index.yaml client ( helm ) and server ( tiller ) component Chartmuseum lightweight Helm chart repository alternatives are Artifactory, Nexus 3, but are heavy \"support all package types\" kind of tools supports different storage options local (e.g., Kubernetes volume) S3 / Minio Google Cloud Storage Azure Blob Store Alibaba Cloud OSS storage Openstack Object Storage Monocular UI for Helm repositories includes documentation and searching can give insight into charts installed in the cluster via helm GitOps https://www.weave.works/blog/gitops-operations-by-pull-request https://www.weave.works/blog/what-is-gitops-really https://www.cloudbees.com/blog/gitops-dev-dash-ops https://developer.atlassian.com/blog/2017/07/kubernetes-workflow/ Thoughts declarative specification for each environment auditable changes ability to verify live what is vs. what should be aside from autoscaling and the like for example, with Kubediff reproducable environments helps automate and spead up Segragation of Duties use PullRequests for change management eventual consistency via event based reconciliation e.g., Git commit event - pipeline - update based on spec Jenkins X - Introduction The challenges Jenkins X tries to solve: good way to setup Kubernetes environments containerize your applications deploy containerized applications to Kubernetes adopt Continuous Delivery / Progressive Delivery base platform for automation keeping focus on delivering value instead of HOW to deliver the value help embed proven practices from the State of DevOps Report How automates installations of all the basic building blocks for CI, CD and PD helm, skaffold, kaniko, jenkins, ksync, knative, nexus, monocular, chartmuseum,... pre-configured, ready to go automates CI/CD setup (PD setup is coming) Docker image Helm chart (Jenkins) Pipeline Event trigger management (e.g., GitHub event triggers for Pipelines) pre-configured GitOps environments + pipelines for managing environment promotion feedback interaction logs, notification hooks, caches labels and comments on GitHub issue / PR PR chatbot Jenkins X - Installation There's four ways to install Jenkins X. install in an existing public cloud Kubernetes cluster jx install create cluster and installation via public cloud's CLI (e.g., gcloud ) create cluster and installation via Terraform (where applicable) install Jenkins X in an on-premise Kubernetes cluster (requirements apply) During the installation, the following things will be done via the jx binary. If you're using Mac OS X, the jx binary will install any missing tool via homebrew . install Helm install cloud provider cli install kubectl create cluster (unless an install only option is used) create Jenkins X namespace install Tiller (unless helm 3 or tillerless is specified) setup basic ingress controller install several CI/CD tools chartmuseum docker-registry jenkins monocular nexus configure git source repository create admin secrets The installation can be configured with flags in order to customize how each step is executed. Default Terraform Install only On-Premis Next Steps create and app via quickstart import and existing app customize your Jenkins X installation Jenkins X - IDE Integration You read all about Jenkins X's IDE integration in the docs . Visual Studio Code Visual Studio Code is a popular open source IDE from Microsoft. The Jenkins X team created the vscode-jx-tools extension for VS Code. Intelli J There's a plugin for IntelliJ and the associated IDEs like WebStorm, GoLand, PyCharm et al from JetBrains . You can find the Jenkins X plugin for IntelliJ here . Jenkins X - Customization Installation Parameters Component Configuration During installation (incl. or excl. cluster creation) Jenkins X will read a myvalues.yaml file in the current directory to configure its core components. You can read more about all the options here , but below are some examples. Nexus You might not want to include Nexus in your installation, the snippet below will exclude it from being installed. 1 2 3 4 5 nexus : enabled : false nexusServiceLink : enabled : true externalName : nexus.jx.svc.cluster.local Chartmuseum Add the below snippet in order to skip installing Chartmuseum. 1 2 3 4 5 chartmuseum : enabled : false chartmuseumServiceLink : enabled : true externalName : jenkins-x-chartmuseum.jx.svc.cluster.local Jenkins image used When using the static Jenkins type of installation, Jenkins X uses the jenkinsxio/jenkinsx docker image. You specify an alternative image in the myvalues.yaml . 1 2 3 4 jenkins : Master : Image : acme/my-jenkinsx ImageTag : 1.2.3 For how to create your custom Jenkins image, read the Jenkins X docs . Alternative Docker Registry Currently - March 2019 - you can only specify the docker registry during the installation ( jx create cluster or jx install ) via a flag. 1 jx create cluster gke --docker-registry eu.gcr.io You will have to configure the docker authentication secret as well. How to do this, you can read in the Jenkins X documentation . Jenkins X - Basic Usage import quickstart console pipelines promote environments applications teams Jenkins X - Other Features Teams https://jenkins-x.io/about/features/#teams JX Shell Create a sub shell so that changes to the Kubernetes context, namespace or environment remain local to the shell 1 2 # create a new shell using a specific named context jx shell prod-cluster JX Prompt Generate the command line prompt for the current team and environment current 1 2 # Generate the current prompt jx prompt bash 1 2 # Enable the prompt for bash PS1 = [\\u@\\h \\W \\$(jx prompt)]\\$ zsh 1 2 # Enable the prompt for zsh PROMPT = $(jx prompt) $PROMPT Issue Tracker Jenkins X can work with issue trackers such as GitHub issues and Jira. By default, Jenkins X will use GitHub for projects and issues. So if you haven't specified anything for either Git provider or Issue tracker, it will use GitHub for issues. GitHub 1 jx create issue -t lets make things more awesome 1 jx get issues Jira In order to configure Jenkins X to use Jira as issue tracker, you have to do three steps. create a tracker configuration jx create tracker server ${trackerName} https://mycompany.atlassian.net/ create a tracker login jx create tracker token -n ${trackerName} myEmailAddress configure your Jenkins X managed project to use this issue tracker instead jx edit config -k issues Info A file called jenkins-x.yml will be modified in your project source code which should be added to your git repository. Security Jenkins X has direct support for some security analysis . Anchore image scanning The Anchore Engine is used to provide image security, by examining contents of containers either in pull request/review state, or on running containers. This was introduced in this blog post . Here is a video demonstrating it live. 1 jx create addon anchore To see if it found any problems in a specific environment: 1 jx get cve --environment = staging OWASP ZAP ZAP or Zed Attack Proxy allows you to scan the public surface of your application for any known vulnerability. 1 jx create addon owasp-zap Jenkins X - Development Cycle Versioning semver semantics using git tags https://github.com/jenkins-x/jx-release-version https://www.cloudbees.com/blog/automatically-versioning-your-application-jenkins-x DevPod https://jenkins-x.io/developing/devpods/ Custom Builder https://jenkins-x.io/getting-started/create-custom-builder/ Preview A new preview is created when you create a PullRequest (PR) on a Jenkins X managed application. builds the application packages it into a Helm chart creates a unique Kubernetes namespace -only on first build deploys the application into the namespace adds a pull request comment with preview environment URL https://jenkins-x.io/about/features/#preview-environments https://jenkins-x.io/developing/preview/#adding-more-resources https://medium.com/@vbehar/zero-cost-preview-environments-on-kubernetes-with-jenkins-x-and-osiris-bd9ce0148d03 https://medium.com/@MichalFoksa/jenkins-x-preview-environment-3bf2424a05e4 Get current preview environments 1 jx get previews Post Preview hook Jenkins X allows you to extend it at several points. One such extension point is the preview process. You can extends the preview process with a post preview hook . Add dependencies Your application might depend on other services or facilities, that are generally present in your staging and production environment. With the move to clusters, these can have become a cluster function, These cluster functions might not be available in your temporary preview environment. Or you want to test your application against multiple versions of its dependencies. So you need the ability to specify these dependencies for the preview of your app which should only be used for the preview environment. This can be done in two ways. link Kubernetes service from other environment /namespace create an instance of a dependency in the preview environment through Helm chart. Link to a service Via the jx step link service you connect your preview app with a Jenkins X managed service elsewhere in the same cluster. Example: 1 jx step link services --from-namespace jx-staging --includes * --excludes cheese* Add helm chart dependency The preview environment has its own helm chart, in the folder charts/preview . You can add dependencies in here, just like in any other helm chart. Just make sure the chart ends with the dependency on your app (in charts/appName ) and an empty line, as the file's comment says. Promotion https://jenkins-x.io/faq/develop/#how-does-promotion-actually-work https://jenkins-x.io/developing/promote/ Jenkins X Secrets https://github.com/futuresimple/helm-secrets https://developer.epages.com/blog/tech-stories/kubernetes-deployments-with-helm-secrets/ vault operator / addon? secrets for preview example: https://github.com/Zenika/snowcamp-2019-sncf-timesheet-reader or this: https://github.com/Riduidel/snowcamp-2019 thanks! helm secrets was the only choice available initially but we\u2019re moving more towards using the vault operator instead - though we need some more docs and demos to show how to use secrets in vault from a Preview or Staging environment - James Strachan Extending Jenkins X https://jenkins-x.io/extending/ Jenkins X CloudBees CodeShip Jenkins X The Future Serverless Jenkins Tekton aka Next Gen(eration) Pipeline Serverless https://medium.com/@jdrawlings/serverless-jenkins-with-jenkins-x-9134cbfe6870 https://github.com/jenkinsci/jenkinsfile-runner Next Gen Pipeline https://www.cloudbees.com/blog/move-toward-next-generation-pipelines https://jenkins-x.io/news/jenkins-x-next-gen-pipeline-engine/ https://github.com/tektoncd/pipeline#-tekton-pipelines https://github.com/jenkins-x/jx/issues/3225 https://jenkins-x.io/getting-started/next-gen-pipeline/ https://github.com/jenkins-x/jx/issues/3223","title":"Jenkins X Introduction"},{"location":"to-be-processed/#jenkins-x-introduction","text":"","title":"Jenkins X Introduction"},{"location":"to-be-processed/#notes-from-slack","text":"","title":"Notes from Slack"},{"location":"to-be-processed/#tips-tricks","text":"https://github.com/jenkinsci/kubernetes-credentials-provider-plugin volume storage with Heptio's Valerio debugging: https://jenkins-x.io/contribute/development/#debugging --gitops mode have to check this jx upgrade platform knative authentication --git-username --org are complimentary, --organisations is unrelated username = the user for the repo's (apps env) org = the organization for the repo's (apps env) e.g.: --git-username joostvdg --org demomon --organisations is used to query GitHub for Quickstarts (no need to specify unless you have alternatives) Jenkins configurations do not persist you can specify them in a ConfigMap though https://github.com/jenkins-x/charts/blob/jenkins/stable/jenkins/templates/config.yaml#L8 credentials used for config can be found here: ~/.jx/jenkinsAuth.yam PodTemplates (static Jenkins) are from the Jenkins Kubernetes Plugin cleanup GKE jx gc gke you can create separate teams with --no-tiller even if the installation was done with Tiller jx init to \"fix\" a outdated ~/.jx folder https://jenkins-x.io/commands/jx_step_credential/ don't do mono repo's why? - https://medium.com/@mattklein123/monorepos-please-dont-e9a279be011b but if you do, https://fuchsia.googlesource.com/jiri/ using a different git provider --git-provider-url .... --git-provider-kind bitbucketserver --git-username foo --git-api-token whatever https://jenkins-x.io/developing/git/#using-a-different-git-provider-for-environments jx start pipeline to manually trigger a pipeline (I assume static Jenkins only) enable GCS for chartmuseum backend https://github.com/jenkins-x/cloud-environments/blob/master/env-jx-infra/myvalues.yaml#L10-L17 jx wraps kubectx tool, so you can use jx ns namespace to change your context to a different namespace faq for diagnosing exposecontroller issues: https://jenkins-x.io/faq/issues/#how-can-i-diagnose-exposecontroller-issues controller is used to generate ingress resources https://github.com/lvlstudio/jenkins-x-builders/tree/master/builder-nodejs-mysql https://github.com/jenkins-x/jx/issues/2550 https://github.com/jenkins-x/jenkins-x-platform/issues/4768 Tillerless: https://jenkins-x.io/news/helm-without-tiller/ difference between jx create quickstart and selecting spring vs. jx create spring jx create spring is an interactive wizard that uses the spring initialiser https://start.spring.io/ jx create quickstart uses a configurable github org to list available existing quickstarts i.e. https://github.com/jenkins-x-quickstarts (edited) multi-cluster support: https://github.com/jenkins-x-charts/environment-controller https://github.com/jenkins-x/jx/issues/479 jx create user ? https://jenkins-x.io/commands/jx_create_jenkins_token/ for problems with wild card certificates doing only one segment (i.e., *.example.com instead of *.*.example.com ) no - we can tweak that. It\u2019s easiest with wildcard - then any exposed service at svc.ns.domain just works - but you could register each namespace in DNS we\u2019ve not exposed that property to the jx install CLI yet - but you could try kubectl edit cm ingress-config urltemplate: {{.Service}}-{{.Namespace}}.{{.Domain}} and then jx upgrade ingress doesn't seem to work yet? (customization gets reverted) alternative, add dns entries to the ingress resources https://jenkins-x.io/getting-started/install-on-cluster/#installing-jenkins-x-on-premise Helm tips tricks for changing secrets https://github.com/helm/helm/blob/master/docs/charts_tips_and_tricks.md#user-content-automatically-roll-deployments-when-configmaps-or-secrets-change how to run integration tests I've answered this in a previous thread. Basically you use the helm chart (which includes the service dependencies as requirements). You create a preview but set the replicaCount for your service to 0 (that way, just the requirements are started). Then just run your tests against the requirements and delete the preview afterwards. Search the channel history for my messages and replicaCount. You should find it. https://jenkins-x.io/faq/develop/#how-do-i-add-other-services-into-a-preview managing static jenkins config has some issues https://github.com/jenkins-x/jx/issues/2991 https://github.com/jenkins-x/jx-docs/issues/1039 https://github.com/helm/charts/pull/9296/files we\u2019re super close from recommending folks use jx create cluster ... --vault --gitops which uses a git repository to store all the configuration changes + versions of stuff - and uses Vault to store all secrets we just merged the last few fixes so it should work for static jenkins servers with the latest jx binary - feb 7 Info It is Ready: jx create cluster gke --vault --gitops --no-tiller","title":"Tips &amp; Tricks"},{"location":"to-be-processed/#multiple-micro-services","text":"if 1 microservice was 1 helm chart with a few different containers for example; you may have a few repos that just make binaries/docker images - then 1 repo which contains the helm chart of the microservice - you can also easily combine microservices together into an uber helm chart - James Strachan we prefer to use multiple repositories so that things are more microservice based. The problem with monorepos is everything gets released on every change; with separate repos its easier to manage change etc to handle changing versions of things across repositories we use updatebot ourselves to do \u2018CI/CD of dependencies\u2019 - we kinda think of it as promotion of dependencies like we promote microservices into environments - its PRs generated as part of the release process the main decision to make really is, , if you have, say, 3 microservices that are fairly tightly coupled; do you combine 3 versions of them all into 1 chart and then release that 1 chart when its all tested together; or do you release the 3 things totally independently - it depeends on coupling and team structure really you can switch from one to the other at any time really https://github.com/jenkins-x/updatebot 1 2 3 4 5 6 7 8 9 10 11 12 # Setup: $ jx create cluster gke -n team1 --default-environment-prefix team1 $ jx create quickstart -p app1 $ jx create quickstart -p app2 $ jx create quickstart -p app3 # The 5 repos: environment-team1-staging environment-team1-production app1 app2 app3","title":"Multiple Micro-services"},{"location":"to-be-processed/#practices-principles","text":"","title":"Practices &amp; Principles"},{"location":"to-be-processed/#principles","text":"Faster time to market Improved deployment frequency Shorter time between fixes Lower failure rate of releases Faster Mean Time To Recovery","title":"Principles"},{"location":"to-be-processed/#practices","text":"Loosely-coupled Architectures Self-service Configuration Automated Provisioning Continuous Build / Integration and Delivery Automated Release Management Incremental Testing Infrastructure Configuration as Code Comprehensive configuration management Trunk based development and feature flags","title":"Practices"},{"location":"to-be-processed/#prerequisites","text":"Primary jx Git Docker Kubernetes Helm Secondary Nexus GitOps Skaffold KNative Prow KSync","title":"Prerequisites"},{"location":"to-be-processed/#jx","text":"","title":"JX"},{"location":"to-be-processed/#git","text":"","title":"Git"},{"location":"to-be-processed/#docker","text":"","title":"Docker"},{"location":"to-be-processed/#kubernetes","text":"any public cloud will do GKE is recommended","title":"Kubernetes"},{"location":"to-be-processed/#validate-cluster-for-jenkins-x-compliance","text":"You can read this article from Viktor Farcic on how to confirm if your cluster is compliant with Jenkins X's requirements. Jenkins X has a binary, called jx , which includes some facilities from the Sonobuoy SDK to provide some validation capabilities.","title":"Validate Cluster for Jenkins X Compliance"},{"location":"to-be-processed/#run-compliance-check","text":"To run the compliance check, just use the jx command below. 1 jx compliance run Warning The compliance check will run for about one hour!","title":"Run compliance check"},{"location":"to-be-processed/#check-compliance-run-status","text":"1 jx compliance status","title":"Check Compliance run status"},{"location":"to-be-processed/#check-compliance-run-logs","text":"1 jx compliance logs -f","title":"Check Compliance run logs"},{"location":"to-be-processed/#see-compliance-run-results","text":"1 jx compliance results","title":"See Compliance run results"},{"location":"to-be-processed/#cleanup","text":"Once you're done with the compliance run, you can clean up any resources it created for the run. 1 jx compliance delete","title":"Cleanup"},{"location":"to-be-processed/#helm","text":"package manager for Kubernetes quivalent to yum install package Kubernetes manifest template (Go templates), packaged and versioned, reffered to as Charts","title":"Helm"},{"location":"to-be-processed/#use-cases","text":"manages packages, repositories and installations manage dependencies to other Charts meaning: you can create bundles allows for customizing standardized installations on Kubernetes for example: MySQL database with specific database, users and settings used as building blocks in other tools separate packaging (Chart) from runtime (application image) there's the chart version and the application version","title":"Use Cases"},{"location":"to-be-processed/#architecture","text":"Helm repository = a hosted index.yaml client ( helm ) and server ( tiller ) component","title":"Architecture"},{"location":"to-be-processed/#chartmuseum","text":"lightweight Helm chart repository alternatives are Artifactory, Nexus 3, but are heavy \"support all package types\" kind of tools supports different storage options local (e.g., Kubernetes volume) S3 / Minio Google Cloud Storage Azure Blob Store Alibaba Cloud OSS storage Openstack Object Storage","title":"Chartmuseum"},{"location":"to-be-processed/#monocular","text":"UI for Helm repositories includes documentation and searching can give insight into charts installed in the cluster via helm","title":"Monocular"},{"location":"to-be-processed/#gitops","text":"https://www.weave.works/blog/gitops-operations-by-pull-request https://www.weave.works/blog/what-is-gitops-really https://www.cloudbees.com/blog/gitops-dev-dash-ops https://developer.atlassian.com/blog/2017/07/kubernetes-workflow/","title":"GitOps"},{"location":"to-be-processed/#thoughts","text":"declarative specification for each environment auditable changes ability to verify live what is vs. what should be aside from autoscaling and the like for example, with Kubediff reproducable environments helps automate and spead up Segragation of Duties use PullRequests for change management eventual consistency via event based reconciliation e.g., Git commit event - pipeline - update based on spec","title":"Thoughts"},{"location":"to-be-processed/#jenkins-x-introduction_1","text":"The challenges Jenkins X tries to solve: good way to setup Kubernetes environments containerize your applications deploy containerized applications to Kubernetes adopt Continuous Delivery / Progressive Delivery base platform for automation keeping focus on delivering value instead of HOW to deliver the value help embed proven practices from the State of DevOps Report","title":"Jenkins X - Introduction"},{"location":"to-be-processed/#how","text":"automates installations of all the basic building blocks for CI, CD and PD helm, skaffold, kaniko, jenkins, ksync, knative, nexus, monocular, chartmuseum,... pre-configured, ready to go automates CI/CD setup (PD setup is coming) Docker image Helm chart (Jenkins) Pipeline Event trigger management (e.g., GitHub event triggers for Pipelines) pre-configured GitOps environments + pipelines for managing environment promotion feedback interaction logs, notification hooks, caches labels and comments on GitHub issue / PR PR chatbot","title":"How"},{"location":"to-be-processed/#jenkins-x-installation","text":"There's four ways to install Jenkins X. install in an existing public cloud Kubernetes cluster jx install create cluster and installation via public cloud's CLI (e.g., gcloud ) create cluster and installation via Terraform (where applicable) install Jenkins X in an on-premise Kubernetes cluster (requirements apply) During the installation, the following things will be done via the jx binary. If you're using Mac OS X, the jx binary will install any missing tool via homebrew . install Helm install cloud provider cli install kubectl create cluster (unless an install only option is used) create Jenkins X namespace install Tiller (unless helm 3 or tillerless is specified) setup basic ingress controller install several CI/CD tools chartmuseum docker-registry jenkins monocular nexus configure git source repository create admin secrets The installation can be configured with flags in order to customize how each step is executed.","title":"Jenkins X - Installation"},{"location":"to-be-processed/#default","text":"","title":"Default"},{"location":"to-be-processed/#terraform","text":"","title":"Terraform"},{"location":"to-be-processed/#install-only","text":"","title":"Install only"},{"location":"to-be-processed/#on-premis","text":"","title":"On-Premis"},{"location":"to-be-processed/#next-steps","text":"create and app via quickstart import and existing app customize your Jenkins X installation","title":"Next Steps"},{"location":"to-be-processed/#jenkins-x-ide-integration","text":"You read all about Jenkins X's IDE integration in the docs .","title":"Jenkins X - IDE Integration"},{"location":"to-be-processed/#visual-studio-code","text":"Visual Studio Code is a popular open source IDE from Microsoft. The Jenkins X team created the vscode-jx-tools extension for VS Code.","title":"Visual Studio Code"},{"location":"to-be-processed/#intelli-j","text":"There's a plugin for IntelliJ and the associated IDEs like WebStorm, GoLand, PyCharm et al from JetBrains . You can find the Jenkins X plugin for IntelliJ here .","title":"Intelli J"},{"location":"to-be-processed/#jenkins-x-customization","text":"","title":"Jenkins X - Customization"},{"location":"to-be-processed/#installation-parameters","text":"","title":"Installation Parameters"},{"location":"to-be-processed/#component-configuration","text":"During installation (incl. or excl. cluster creation) Jenkins X will read a myvalues.yaml file in the current directory to configure its core components. You can read more about all the options here , but below are some examples.","title":"Component Configuration"},{"location":"to-be-processed/#nexus","text":"You might not want to include Nexus in your installation, the snippet below will exclude it from being installed. 1 2 3 4 5 nexus : enabled : false nexusServiceLink : enabled : true externalName : nexus.jx.svc.cluster.local","title":"Nexus"},{"location":"to-be-processed/#chartmuseum_1","text":"Add the below snippet in order to skip installing Chartmuseum. 1 2 3 4 5 chartmuseum : enabled : false chartmuseumServiceLink : enabled : true externalName : jenkins-x-chartmuseum.jx.svc.cluster.local","title":"Chartmuseum"},{"location":"to-be-processed/#jenkins-image-used","text":"When using the static Jenkins type of installation, Jenkins X uses the jenkinsxio/jenkinsx docker image. You specify an alternative image in the myvalues.yaml . 1 2 3 4 jenkins : Master : Image : acme/my-jenkinsx ImageTag : 1.2.3 For how to create your custom Jenkins image, read the Jenkins X docs .","title":"Jenkins image used"},{"location":"to-be-processed/#alternative-docker-registry","text":"Currently - March 2019 - you can only specify the docker registry during the installation ( jx create cluster or jx install ) via a flag. 1 jx create cluster gke --docker-registry eu.gcr.io You will have to configure the docker authentication secret as well. How to do this, you can read in the Jenkins X documentation .","title":"Alternative Docker Registry"},{"location":"to-be-processed/#jenkins-x-basic-usage","text":"import quickstart console pipelines promote environments applications teams","title":"Jenkins X - Basic Usage"},{"location":"to-be-processed/#jenkins-x-other-features","text":"","title":"Jenkins X - Other Features"},{"location":"to-be-processed/#teams","text":"https://jenkins-x.io/about/features/#teams","title":"Teams"},{"location":"to-be-processed/#jx-shell","text":"Create a sub shell so that changes to the Kubernetes context, namespace or environment remain local to the shell 1 2 # create a new shell using a specific named context jx shell prod-cluster","title":"JX Shell"},{"location":"to-be-processed/#jx-prompt","text":"Generate the command line prompt for the current team and environment current 1 2 # Generate the current prompt jx prompt bash 1 2 # Enable the prompt for bash PS1 = [\\u@\\h \\W \\$(jx prompt)]\\$ zsh 1 2 # Enable the prompt for zsh PROMPT = $(jx prompt) $PROMPT","title":"JX Prompt"},{"location":"to-be-processed/#issue-tracker","text":"Jenkins X can work with issue trackers such as GitHub issues and Jira. By default, Jenkins X will use GitHub for projects and issues. So if you haven't specified anything for either Git provider or Issue tracker, it will use GitHub for issues.","title":"Issue Tracker"},{"location":"to-be-processed/#github","text":"1 jx create issue -t lets make things more awesome 1 jx get issues","title":"GitHub"},{"location":"to-be-processed/#jira","text":"In order to configure Jenkins X to use Jira as issue tracker, you have to do three steps. create a tracker configuration jx create tracker server ${trackerName} https://mycompany.atlassian.net/ create a tracker login jx create tracker token -n ${trackerName} myEmailAddress configure your Jenkins X managed project to use this issue tracker instead jx edit config -k issues Info A file called jenkins-x.yml will be modified in your project source code which should be added to your git repository.","title":"Jira"},{"location":"to-be-processed/#security","text":"Jenkins X has direct support for some security analysis .","title":"Security"},{"location":"to-be-processed/#anchore-image-scanning","text":"The Anchore Engine is used to provide image security, by examining contents of containers either in pull request/review state, or on running containers. This was introduced in this blog post . Here is a video demonstrating it live. 1 jx create addon anchore To see if it found any problems in a specific environment: 1 jx get cve --environment = staging","title":"Anchore image scanning"},{"location":"to-be-processed/#owasp-zap","text":"ZAP or Zed Attack Proxy allows you to scan the public surface of your application for any known vulnerability. 1 jx create addon owasp-zap","title":"OWASP ZAP"},{"location":"to-be-processed/#jenkins-x-development-cycle","text":"","title":"Jenkins X - Development Cycle"},{"location":"to-be-processed/#versioning","text":"semver semantics using git tags https://github.com/jenkins-x/jx-release-version https://www.cloudbees.com/blog/automatically-versioning-your-application-jenkins-x","title":"Versioning"},{"location":"to-be-processed/#devpod","text":"https://jenkins-x.io/developing/devpods/","title":"DevPod"},{"location":"to-be-processed/#custom-builder","text":"https://jenkins-x.io/getting-started/create-custom-builder/","title":"Custom Builder"},{"location":"to-be-processed/#preview","text":"A new preview is created when you create a PullRequest (PR) on a Jenkins X managed application. builds the application packages it into a Helm chart creates a unique Kubernetes namespace -only on first build deploys the application into the namespace adds a pull request comment with preview environment URL https://jenkins-x.io/about/features/#preview-environments https://jenkins-x.io/developing/preview/#adding-more-resources https://medium.com/@vbehar/zero-cost-preview-environments-on-kubernetes-with-jenkins-x-and-osiris-bd9ce0148d03 https://medium.com/@MichalFoksa/jenkins-x-preview-environment-3bf2424a05e4","title":"Preview"},{"location":"to-be-processed/#get-current-preview-environments","text":"1 jx get previews","title":"Get current preview environments"},{"location":"to-be-processed/#post-preview-hook","text":"Jenkins X allows you to extend it at several points. One such extension point is the preview process. You can extends the preview process with a post preview hook .","title":"Post Preview hook"},{"location":"to-be-processed/#add-dependencies","text":"Your application might depend on other services or facilities, that are generally present in your staging and production environment. With the move to clusters, these can have become a cluster function, These cluster functions might not be available in your temporary preview environment. Or you want to test your application against multiple versions of its dependencies. So you need the ability to specify these dependencies for the preview of your app which should only be used for the preview environment. This can be done in two ways. link Kubernetes service from other environment /namespace create an instance of a dependency in the preview environment through Helm chart.","title":"Add dependencies"},{"location":"to-be-processed/#link-to-a-service","text":"Via the jx step link service you connect your preview app with a Jenkins X managed service elsewhere in the same cluster. Example: 1 jx step link services --from-namespace jx-staging --includes * --excludes cheese*","title":"Link to a service"},{"location":"to-be-processed/#add-helm-chart-dependency","text":"The preview environment has its own helm chart, in the folder charts/preview . You can add dependencies in here, just like in any other helm chart. Just make sure the chart ends with the dependency on your app (in charts/appName ) and an empty line, as the file's comment says.","title":"Add helm chart dependency"},{"location":"to-be-processed/#promotion","text":"https://jenkins-x.io/faq/develop/#how-does-promotion-actually-work https://jenkins-x.io/developing/promote/","title":"Promotion"},{"location":"to-be-processed/#jenkins-x-secrets","text":"https://github.com/futuresimple/helm-secrets https://developer.epages.com/blog/tech-stories/kubernetes-deployments-with-helm-secrets/ vault operator / addon? secrets for preview example: https://github.com/Zenika/snowcamp-2019-sncf-timesheet-reader or this: https://github.com/Riduidel/snowcamp-2019 thanks! helm secrets was the only choice available initially but we\u2019re moving more towards using the vault operator instead - though we need some more docs and demos to show how to use secrets in vault from a Preview or Staging environment - James Strachan","title":"Jenkins X &amp; Secrets"},{"location":"to-be-processed/#extending-jenkins-x","text":"https://jenkins-x.io/extending/","title":"Extending Jenkins X"},{"location":"to-be-processed/#jenkins-x-cloudbees-codeship","text":"","title":"Jenkins X &amp; CloudBees CodeShip"},{"location":"to-be-processed/#jenkins-x-the-future","text":"Serverless Jenkins Tekton aka Next Gen(eration) Pipeline","title":"Jenkins X &amp; The Future"},{"location":"to-be-processed/#serverless","text":"https://medium.com/@jdrawlings/serverless-jenkins-with-jenkins-x-9134cbfe6870 https://github.com/jenkinsci/jenkinsfile-runner","title":"Serverless"},{"location":"to-be-processed/#next-gen-pipeline","text":"https://www.cloudbees.com/blog/move-toward-next-generation-pipelines https://jenkins-x.io/news/jenkins-x-next-gen-pipeline-engine/ https://github.com/tektoncd/pipeline#-tekton-pipelines https://github.com/jenkins-x/jx/issues/3225 https://jenkins-x.io/getting-started/next-gen-pipeline/ https://github.com/jenkins-x/jx/issues/3223","title":"Next Gen Pipeline"},{"location":"buildpack/","text":"BuildPack notes location of jx default packs: https://github.com/jenkins-x-buildpacks/jenkins-x-kubernetes location of local ones we can edit: ~/.jx/draft/packs/github.com/jenkins-x-buildpacks/jenkins-x-kubernetes Copy existing First, make a fork of https://github.com/$GH_USER/jenkins-x-kubernetes in your own repo. 1 GH_USER = ? 1 2 git clone https://github.com/ $GH_USER /jenkins-x-kubernetes cd jenkins-x-kubernetes Confirm the packs are there: 1 ls -1 packs Let's look at the Gradle one - the one closest to what we need. 1 ls -1 packs/gradle 1 cp -R packs/gradle packs/micronaut-gradle-redis 1 ls -1 packs/micronaut-gradle-redis Fix Dockerfile Raw Dockerfile 1 2 3 4 FROM openjdk:8u171-alpine3.7 RUN apk --no-cache add curl COPY build/libs/*-all.jar complete.jar CMD java ${JAVA_OPTS} -jar complete.jar CommandLine magic 1 2 3 4 5 rm packs/micronaut-gradle-redis/Dockerfile echo FROM openjdk:8u171-alpine3.7 RUN apk --no-cache add curl COPY build/libs/*-all.jar complete.jar CMD java ${ JAVA_OPTS } -jar complete.jar | tee packs/micronaut-gradle-redis/Dockerfile Fix health check We have to change the value of probePath , from /actuator/health to /health . So please edit packs/micronaut-gradle-redis/charts/values.yaml to reflect the change or use the below yq command. yq 1 yq w packs/micronaut-gradle-redis/charts/values.yaml --inplace probePath /health Configure Redis deployment.yaml packs/micronaut-gradle-redis/charts/templates/deployment.yaml Raw YAML 1 2 3 env : - name : REDIS_HOST value : {{ template fullname . }} -redis-master Command Line magic 1 2 3 4 5 cat packs/micronaut-gradle-redis/charts/templates/deployment.yaml | sed -e \\ s@env:@env:\\ - name: REDIS_HOST\\ value: {{ template fullname . }}-redis-master@g \\ | tee packs/micronaut-gradle-redis/charts/templates/deployment.yaml values.yaml Raw YAML 1 2 REPLACE_ME_APP_NAME-redis : usePassword : false CommandLine Magic 1 2 3 echo REPLACE_ME_APP_NAME-redis: usePassword: false | tee -a packs/micronaut-gradle-redis/charts/values.yaml requirements.yaml packs/micronaut-gradle-redis/charts/requirements.yaml Warning Please note the usage of the REPLACE_ME_APP_NAME string. Today (April 2019), that is still one of the features that are not documented. When the build pack is applied, it'll replace that string with the actual name of the application. After all, it would be silly to hard-code the name of the application since this pack should be reusable across many. Raw YAML 1 2 3 4 5 dependencies : - alias : REPLACE_ME_APP_NAME-redis name : redis repository : https://kubernetes-charts.storage.googleapis.com version : 6.1.0 CommandLine magic 1 2 3 4 5 6 echo dependencies: - alias: REPLACE_ME_APP_NAME-redis name: redis repository: https://kubernetes-charts.storage.googleapis.com version: 6.1.0 | tee packs/micronaut-gradle-redis/charts/requirements.yaml Preview requirements packs/micronaut-gradle-redis/preview/requirements.yaml Info The file states: \"alias: preview\" must be last entry in dependencies array Place custom dependencies above We will have to change the file to include our Redis requirement. Which means, this part: 1 2 3 4 5 # !! alias: preview must be last entry in dependencies array !! # !! Place custom dependencies above !! - alias : preview name : REPLACE_ME_APP_NAME repository : file://../REPLACE_ME_APP_NAME Should look like: Expected End Result 1 2 3 4 5 6 7 8 9 10 - alias : preview-redis name : REPLACE_ME_APP_NAME-redis repository : https://kubernetes-charts.storage.googleapis.com version : 6.1.0 # !! alias: preview must be last entry in dependencies array !! # !! Place custom dependencies above !! - alias : preview name : REPLACE_ME_APP_NAME repository : file://../REPLACE_ME_APP_NAME CommandLine Magic 1 2 3 4 5 6 7 8 9 10 11 12 cat packs/micronaut-gradle-redis/preview/requirements.yaml \\ | sed -e \\ s@ # !! alias@- name: REPLACE_ME_APP_NAME-redis\\ alias: preview-redis\\ version: 6.1.0\\ repository: https://kubernetes-charts.storage.googleapis.com\\ \\ # !! alias@g \\ | tee packs/micronaut-gradle-redis/preview/requirements.yaml echo | tee -a packs/micronaut-gradle-redis/preview/requirements.yaml Commit and go 1 2 3 4 5 git add . git commit -m Added micronaut-gradle-redis build pack git push Add to known buildpacks With the new build pack safely stored, we should let Jenkins X know that we want to use the forked repository. We can use jx edit buildpack to change the location of our kubernetes-workloads packs. However, at the time of this writing (February 2019), there is a bug that prevents us from doing that ( issue 2955 ). The good news is that there is a workaround. If we omit the name ( -n or --name ), Jenkins X will add the new packs location, instead of editing the one dedicated to kubernetes-workloads packs. 1 2 3 4 jx edit buildpack \\ -u https://github.com/ $GH_USER /jenkins-x-kubernetes \\ -r master \\ -b Test new BuildPack make sure we're back at jx-micronaut-seed project lets reset it Reset application 1 2 3 4 5 6 7 8 9 10 11 git checkout orig git merge -s ours master --no-edit git checkout master git merge orig rm -rf charts git push Remove application from Jenkins X Removes the application from Jenkins X. 1 jx delete application $GH_USER /jx-micronaut-seed -b And the following removes the activities of the application from Kubernetes. 1 2 kubectl -n jx delete act -l owner = $GH_USER \\ -l sourcerepository = $GH_USER -jx-micronaut-seed Import 1 2 3 4 jx import --pack micronaut-gradle-redis -b ls -1 \\ ~/.jx/draft/packs/github.com/ $GH_USER /jenkins-x-kubernetes/packs Info If you run into the problem that the build fails, because the Helm Chart already exists in Chartmuseum: Received 409 response: { error : file already exists } . You can solve this by creating and pushing git tag with a higher version via jx binary. 1 2 jx step tag --version 0 .2.0 git push Info For more information on how to version your application, please consult jx-release-version . Confirm it works Let's watch the activity stream, to see when our application lands in staging. 1 jx get activity -f jx-micronaut-seed -w Once it succeeds, we can see if the applications does run now. 1 kubectl get pods -n jx-staging -l app = jx-jx-micronaut-seed It should now be running: 1 2 NAME READY STATUS RESTARTS AGE jx-jx-micronaut-seed-75ffd4fbc4-66sgr 1 /1 Running 0 9m Let's see if we can talk to it. curl 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR /health httpie 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) http $APP_ADDR /health The answer is: 1 2 3 { status : UP }","title":"BuildPack"},{"location":"buildpack/#buildpack-notes","text":"location of jx default packs: https://github.com/jenkins-x-buildpacks/jenkins-x-kubernetes location of local ones we can edit: ~/.jx/draft/packs/github.com/jenkins-x-buildpacks/jenkins-x-kubernetes","title":"BuildPack notes"},{"location":"buildpack/#copy-existing","text":"First, make a fork of https://github.com/$GH_USER/jenkins-x-kubernetes in your own repo. 1 GH_USER = ? 1 2 git clone https://github.com/ $GH_USER /jenkins-x-kubernetes cd jenkins-x-kubernetes Confirm the packs are there: 1 ls -1 packs Let's look at the Gradle one - the one closest to what we need. 1 ls -1 packs/gradle 1 cp -R packs/gradle packs/micronaut-gradle-redis 1 ls -1 packs/micronaut-gradle-redis","title":"Copy existing"},{"location":"buildpack/#fix-dockerfile","text":"Raw Dockerfile 1 2 3 4 FROM openjdk:8u171-alpine3.7 RUN apk --no-cache add curl COPY build/libs/*-all.jar complete.jar CMD java ${JAVA_OPTS} -jar complete.jar CommandLine magic 1 2 3 4 5 rm packs/micronaut-gradle-redis/Dockerfile echo FROM openjdk:8u171-alpine3.7 RUN apk --no-cache add curl COPY build/libs/*-all.jar complete.jar CMD java ${ JAVA_OPTS } -jar complete.jar | tee packs/micronaut-gradle-redis/Dockerfile","title":"Fix Dockerfile"},{"location":"buildpack/#fix-health-check","text":"We have to change the value of probePath , from /actuator/health to /health . So please edit packs/micronaut-gradle-redis/charts/values.yaml to reflect the change or use the below yq command. yq 1 yq w packs/micronaut-gradle-redis/charts/values.yaml --inplace probePath /health","title":"Fix health check"},{"location":"buildpack/#configure-redis","text":"","title":"Configure Redis"},{"location":"buildpack/#deploymentyaml","text":"packs/micronaut-gradle-redis/charts/templates/deployment.yaml Raw YAML 1 2 3 env : - name : REDIS_HOST value : {{ template fullname . }} -redis-master Command Line magic 1 2 3 4 5 cat packs/micronaut-gradle-redis/charts/templates/deployment.yaml | sed -e \\ s@env:@env:\\ - name: REDIS_HOST\\ value: {{ template fullname . }}-redis-master@g \\ | tee packs/micronaut-gradle-redis/charts/templates/deployment.yaml","title":"deployment.yaml"},{"location":"buildpack/#valuesyaml","text":"Raw YAML 1 2 REPLACE_ME_APP_NAME-redis : usePassword : false CommandLine Magic 1 2 3 echo REPLACE_ME_APP_NAME-redis: usePassword: false | tee -a packs/micronaut-gradle-redis/charts/values.yaml","title":"values.yaml"},{"location":"buildpack/#requirementsyaml","text":"packs/micronaut-gradle-redis/charts/requirements.yaml Warning Please note the usage of the REPLACE_ME_APP_NAME string. Today (April 2019), that is still one of the features that are not documented. When the build pack is applied, it'll replace that string with the actual name of the application. After all, it would be silly to hard-code the name of the application since this pack should be reusable across many. Raw YAML 1 2 3 4 5 dependencies : - alias : REPLACE_ME_APP_NAME-redis name : redis repository : https://kubernetes-charts.storage.googleapis.com version : 6.1.0 CommandLine magic 1 2 3 4 5 6 echo dependencies: - alias: REPLACE_ME_APP_NAME-redis name: redis repository: https://kubernetes-charts.storage.googleapis.com version: 6.1.0 | tee packs/micronaut-gradle-redis/charts/requirements.yaml","title":"requirements.yaml"},{"location":"buildpack/#preview-requirements","text":"packs/micronaut-gradle-redis/preview/requirements.yaml Info The file states: \"alias: preview\" must be last entry in dependencies array Place custom dependencies above We will have to change the file to include our Redis requirement. Which means, this part: 1 2 3 4 5 # !! alias: preview must be last entry in dependencies array !! # !! Place custom dependencies above !! - alias : preview name : REPLACE_ME_APP_NAME repository : file://../REPLACE_ME_APP_NAME Should look like: Expected End Result 1 2 3 4 5 6 7 8 9 10 - alias : preview-redis name : REPLACE_ME_APP_NAME-redis repository : https://kubernetes-charts.storage.googleapis.com version : 6.1.0 # !! alias: preview must be last entry in dependencies array !! # !! Place custom dependencies above !! - alias : preview name : REPLACE_ME_APP_NAME repository : file://../REPLACE_ME_APP_NAME CommandLine Magic 1 2 3 4 5 6 7 8 9 10 11 12 cat packs/micronaut-gradle-redis/preview/requirements.yaml \\ | sed -e \\ s@ # !! alias@- name: REPLACE_ME_APP_NAME-redis\\ alias: preview-redis\\ version: 6.1.0\\ repository: https://kubernetes-charts.storage.googleapis.com\\ \\ # !! alias@g \\ | tee packs/micronaut-gradle-redis/preview/requirements.yaml echo | tee -a packs/micronaut-gradle-redis/preview/requirements.yaml","title":"Preview requirements"},{"location":"buildpack/#commit-and-go","text":"1 2 3 4 5 git add . git commit -m Added micronaut-gradle-redis build pack git push","title":"Commit and go"},{"location":"buildpack/#add-to-known-buildpacks","text":"With the new build pack safely stored, we should let Jenkins X know that we want to use the forked repository. We can use jx edit buildpack to change the location of our kubernetes-workloads packs. However, at the time of this writing (February 2019), there is a bug that prevents us from doing that ( issue 2955 ). The good news is that there is a workaround. If we omit the name ( -n or --name ), Jenkins X will add the new packs location, instead of editing the one dedicated to kubernetes-workloads packs. 1 2 3 4 jx edit buildpack \\ -u https://github.com/ $GH_USER /jenkins-x-kubernetes \\ -r master \\ -b","title":"Add to known buildpacks"},{"location":"buildpack/#test-new-buildpack","text":"make sure we're back at jx-micronaut-seed project lets reset it","title":"Test new BuildPack"},{"location":"buildpack/#reset-application","text":"1 2 3 4 5 6 7 8 9 10 11 git checkout orig git merge -s ours master --no-edit git checkout master git merge orig rm -rf charts git push","title":"Reset application"},{"location":"buildpack/#remove-application-from-jenkins-x","text":"Removes the application from Jenkins X. 1 jx delete application $GH_USER /jx-micronaut-seed -b And the following removes the activities of the application from Kubernetes. 1 2 kubectl -n jx delete act -l owner = $GH_USER \\ -l sourcerepository = $GH_USER -jx-micronaut-seed","title":"Remove application from Jenkins X"},{"location":"buildpack/#import","text":"1 2 3 4 jx import --pack micronaut-gradle-redis -b ls -1 \\ ~/.jx/draft/packs/github.com/ $GH_USER /jenkins-x-kubernetes/packs Info If you run into the problem that the build fails, because the Helm Chart already exists in Chartmuseum: Received 409 response: { error : file already exists } . You can solve this by creating and pushing git tag with a higher version via jx binary. 1 2 jx step tag --version 0 .2.0 git push Info For more information on how to version your application, please consult jx-release-version .","title":"Import"},{"location":"buildpack/#confirm-it-works","text":"Let's watch the activity stream, to see when our application lands in staging. 1 jx get activity -f jx-micronaut-seed -w Once it succeeds, we can see if the applications does run now. 1 kubectl get pods -n jx-staging -l app = jx-jx-micronaut-seed It should now be running: 1 2 NAME READY STATUS RESTARTS AGE jx-jx-micronaut-seed-75ffd4fbc4-66sgr 1 /1 Running 0 9m Let's see if we can talk to it. curl 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR /health httpie 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) http $APP_ADDR /health The answer is: 1 2 3 { status : UP }","title":"Confirm it works"},{"location":"buildpack/import/","text":"Import Existing Project Tip As we will have to edit yaml files, I can recommend using a commandline yaml editor. One such is mikefarah's yq . Snap 1 snap install yq Homebrew 1 brew install yq Another tip, for testing URL's, instead of using CURL, I would recommend HTTPie . Debian based 1 apt-get install httpie RHEL based 1 yum install httpie Homebrew 1 brew install httpie Windows via Python 1 2 pip install --upgrade pip setuptools pip install --upgrade httpie Config Replace ? with your GitHub user where you will be working from. 1 GH_USER = ? Fork example project Fork github.com/demomon/jx-micronaut-seed as a start. And then checkout your version of the project and go into the project's directory. SSH 1 2 git clone git@github.com: ${ GH_USER } /jx-micronaut-seed.git \\ cd jx-micronaut-seed https 1 2 git clone https://github.com/ ${ GH_USER } /jx-micronaut-seed.git \\ cd jx-micronaut-seed Import in JX Info When in doubt, accept the defaults of the prompts asking questions. 1 jx import You should see, among other things, the following logs. 1 2 3 selected pack: /Users/joostvdg/.jx/draft/packs/github.com/jenkins-x-buildpacks/jenkins-x-kubernetes/packs/gradle replacing placeholders in directory /Users/joostvdg/Projects/Personal/Github/jx-micronaut-seed app name: jx-micronaut-seed, git server: github.com, org: joostvdg, Docker registry org: joostvdg Jenkins X - via Draft - automatically detected this application is being build with Gradle . As you can see in the highlighted section in the code snippet above. Confirm the application is building The application will fail to build, as the default Dockerfile is not correct. Use the below code to replace the Dockerfile. 1 2 3 4 FROM openjdk:8u171-alpine3.7 RUN apk --no-cache add curl COPY build/libs/*-all.jar complete.jar CMD java ${JAVA_OPTS} -jar complete.jar Commit your change and watch the activity. 1 2 3 4 git add Dockerfile git commit -m fix Dockerfile git push jx get activity -f jx-micronaut-seed -w Once the Promote: staging is completed successfully, we should be able to test if the application is running! 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR You should see something like this: 1 2 3 4 5 6 7 html head title 503 Service Temporarily Unavailable / title / head body center h1 503 Service Temporarily Unavailable / h1 / center hr center nginx/1.15.8 / center / body / html Something is wrong... Find out what is wrong To find out what is wrong, lets check the pod status. 1 kubectl get pods -n jx-staging -l app = jx-jx-micronaut-seed We should see something as follows. 1 2 NAME READY STATUS RESTARTS AGE jx-jx-micronaut-seed-68f4bffb7b-mpb57 0 /1 CrashLoopBackOff 41 1h Let's describe the pod and see what is causing the CrashLoopBackOff . 1 kubectl describe pods -n jx-staging -l app = jx-jx-micronaut-seed If we look at the Events: section, we will see something like this: 1 2 3 4 5 6 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning Unhealthy 13m ( x1833 over 16h ) kubelet, gke-joostvdg-default-pool-6f512cf8-7l4l Readiness probe failed: HTTP probe failed with statuscode: 404 Normal Pulled 8m43s ( x240 over 16h ) kubelet, gke-joostvdg-default-pool-6f512cf8-7l4l Container image 10.23.250.118:5000/joostvdg/jx-micronaut-seed:0.0.3 already present on machine Warning BackOff 3m34s ( x2866 over 16h ) kubelet, gke-joostvdg-default-pool-6f512cf8-7l4l Back-off restarting failed container One of the things you can spot, is Readiness probe failed: HTTP probe failed with statuscode: 404 . Assuming our application is flawless - it passed it build test phase - it's likely that Kubernetes is looking at a non-existing endpoint for a health check. Fix Health Check As good as Jenkins X is, it isn't clairvoyant and cannot detect that our Micronaut application has a different health check endpoint. You might not know what the Micronaut framework gives you, but I can tell you. The health check endpoint is located at /health , not a bad place to put it. As the Gradle BuildPack is designed with Spring Boot in mind, it directs Kubernetes health check to /actuator/health . So we have to change this. Our application is packaged by Helm and the values for our Kubernetes Deployment - where the health check is configured - are located in /charts/jx-micronaut-seed/values.yaml . We have to change the value of probePath , from /actuator/health to /health . So please edit /charts/jx-micronaut-seed/values.yaml to reflect the change or use the below yq command. This should be the end result: 1 2 3 4 5 6 7 8 9 10 11 12 13 ... cpu : 500m memory : 512Mi requests : cpu : 400m memory : 512Mi probePath : /health livenessProbe : initialDelaySeconds : 60 periodSeconds : 10 successThreshold : 1 timeoutSeconds : 1 ... yq 1 yq w charts/jx-micronaut-seed/values.yaml --inplace probePath /health Now commit and push our change to fix our deployment! 1 2 3 4 git add charts/jx-micronaut-seed/values.yaml git commit -m fix health check endpoint git push jx get activity -f jx-micronaut-seed -w Once the applications is successfully promoted to staging, we can try again! 1 kubectl get pods -n jx-staging -l app = jx-jx-micronaut-seed Oh no, the application is still not running! 1 2 NAME READY STATUS RESTARTS AGE jx-jx-micronaut-seed-d5498679f-55b84 0 /1 Running 1 2m Still broken Let's describe the pod and see what is wrong this time. 1 kubectl describe pods -n jx-staging -l app = jx-jx-micronaut-seed 1 2 3 Warning Unhealthy 94s ( x2 over 3m14s ) kubelet, gke-joostvdg-default-pool-6f512cf8-41l4 Readiness probe failed: Get http://10.20.0.24:8080/health: dial tcp 10 .20.0.24:8080: connect: connection refused Warning Unhealthy 83s ( x2 over 3m3s ) kubelet, gke-joostvdg-default-pool-6f512cf8-41l4 Readiness probe failed: Get http://10.20.0.24:8080/health: net/http: request canceled ( Client.Timeout exceeded while awaiting headers ) Warning Unhealthy 54s ( x11 over 2m54s ) kubelet, gke-joostvdg-default-pool-6f512cf8-41l4 Readiness probe failed: HTTP probe failed with statuscode: 500 It seems our application is not getting into ready state: Readiness probe failed: HTTP probe failed with statuscode: 500 . Now this is a bit of cheat, because this application actually requires a connection with a Redis database in order to function. It can be build without it fine, and it will run fine, but Micronaut 's health check endpoint will incorporate the Redis connection into it's health status. Configure Redis database This means we must make sure our application can talk to a Redis database! Add Redis dependency The easiest way to do this with Jenkins X , is to add a dependency to our Helm Chart . If our dependency exists as a health chart, that is. Just our luck, looking at Helm Stable Charts , there's a Redis chart we can add. To do so, we add a requirements.yaml to our Chart. Create a file charts/jx-micronaut-seed/requirements.yaml and fill in the below details. Raw YAML 1 2 3 4 5 dependencies : - alias : jx-micronaut-seed-redis name : redis repository : https://kubernetes-charts.storage.googleapis.com version : 6.1.0 CommandLine magic 1 2 3 4 5 6 echo dependencies: - alias: jx-micronaut-seed-redis name: redis repository: https://kubernetes-charts.storage.googleapis.com version: 6.1.0 | tee charts/jx-micronaut-seed/requirements.yaml Application Redis config To be safe that whenever our application gets deployed via Helm it can find our database, we need to make sure the location it looks for is a variable. We can add this in three places, either in the application itself, in our values.yaml or in our deployment.yaml template. Our application will get deployed via Helm, which means the name it gets and the Redis dependency gets, will depend on the Helm release name. So in this particular case, it's best to add an environment variable to the deployment template. With a default value, that derives its value from the Helm release name. This makes the default install from Helm work and allows users of our Helm chart, to use a different Redis instance. To do so, we have to add the environment variable in charts/jx-micronaut-seed/templates/deployment.yaml . Add the below snippet to the spec.template.spec.containers[0] section between imagePullPolicy: {{ .Values.image.pullPolicy }} and ports: . Raw YAML 1 2 3 env : - name : REDIS_HOST value : {{ template fullname . }} -redis-master Command Line magic 1 2 3 4 5 cat charts/jx-micronaut-seed/templates/deployment.yaml | sed -e \\ s@env:@env:\\ - name: REDIS_HOST\\ value: {{ template fullname . }}-redis-master@g \\ | tee charts/jx-micronaut-seed/templates/deployment.yaml The end result should look like this: 1 2 3 4 5 6 7 8 9 spec : containers : - name : {{ .Chart.Name }} image : {{ .Values.image.repository }}:{{ .Values.image.tag }} imagePullPolicy : {{ .Values.image.pullPolicy }} env : - name : REDIS_HOST value : {{ template fullname . }} -redis-master ports : Redis Chart config We need to do one last thing. The Redis chart by default generates a unique password on startup. This is nice and secure, but makes it difficult for our application to connect to it. Let's configure our Redis chart to not use a password for now. Add the below snippet at the bottom of charts/jx-micronaut-seed/values.yaml or use the command line magic for automation. Raw YAML 1 2 jx-micronaut-seed-redis : usePassword : false Command Line magic 1 2 3 echo jx-micronaut-seed-redis: usePassword: false | tee -a charts/jx-micronaut-seed/values.yaml Commit and confirm Let's commit and push our changes and see if this was enough! 1 2 3 4 5 6 git add charts/jx-micronaut-seed/templates/deployment.yaml git add charts/jx-micronaut-seed/values.yaml git add charts/jx-micronaut-seed/requirements.yaml git commit -m add and configure redis dependency git push jx get activity -f jx-micronaut-seed -w Confirm it works Once it succeeds, we can see if the applications does run now. 1 kubectl get pods -n jx-staging -l app = jx-jx-micronaut-seed It should now be running: 1 2 NAME READY STATUS RESTARTS AGE jx-jx-micronaut-seed-75ffd4fbc4-66sgr 1 /1 Running 0 9m Let's see if we can talk to it. curl 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR /health httpie 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) http $APP_ADDR /health The answer is: 1 2 3 { status : UP } We've done it! Now lets use the Redis database in a wholefully inappropriate way. curl 1 2 3 4 5 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) curl --header Content-Type: application/json \\ --request POST --data { body : Something curl , sender : Joost } \\ http:// $APP_ADDR /message curl http:// $APP_ADDR /message httpie 1 2 3 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) http POST ${ APP_ADDR } /message body = Something httpie sender = Joost http ${ APP_ADDR } /message Now, in order to avoid having to this kind of ritual for every Micronaut based application, we should probably make a better starting point. Let's move on to create a BuildPack Info For more information on Jenkins X's jx import command, please consult the documentation at jenkins-x.io","title":"Import"},{"location":"buildpack/import/#import-existing-project","text":"","title":"Import Existing Project"},{"location":"buildpack/import/#tip","text":"As we will have to edit yaml files, I can recommend using a commandline yaml editor. One such is mikefarah's yq . Snap 1 snap install yq Homebrew 1 brew install yq Another tip, for testing URL's, instead of using CURL, I would recommend HTTPie . Debian based 1 apt-get install httpie RHEL based 1 yum install httpie Homebrew 1 brew install httpie Windows via Python 1 2 pip install --upgrade pip setuptools pip install --upgrade httpie","title":"Tip"},{"location":"buildpack/import/#config","text":"Replace ? with your GitHub user where you will be working from. 1 GH_USER = ?","title":"Config"},{"location":"buildpack/import/#fork-example-project","text":"Fork github.com/demomon/jx-micronaut-seed as a start. And then checkout your version of the project and go into the project's directory. SSH 1 2 git clone git@github.com: ${ GH_USER } /jx-micronaut-seed.git \\ cd jx-micronaut-seed https 1 2 git clone https://github.com/ ${ GH_USER } /jx-micronaut-seed.git \\ cd jx-micronaut-seed","title":"Fork example project"},{"location":"buildpack/import/#import-in-jx","text":"Info When in doubt, accept the defaults of the prompts asking questions. 1 jx import You should see, among other things, the following logs. 1 2 3 selected pack: /Users/joostvdg/.jx/draft/packs/github.com/jenkins-x-buildpacks/jenkins-x-kubernetes/packs/gradle replacing placeholders in directory /Users/joostvdg/Projects/Personal/Github/jx-micronaut-seed app name: jx-micronaut-seed, git server: github.com, org: joostvdg, Docker registry org: joostvdg Jenkins X - via Draft - automatically detected this application is being build with Gradle . As you can see in the highlighted section in the code snippet above.","title":"Import in JX"},{"location":"buildpack/import/#confirm-the-application-is-building","text":"The application will fail to build, as the default Dockerfile is not correct. Use the below code to replace the Dockerfile. 1 2 3 4 FROM openjdk:8u171-alpine3.7 RUN apk --no-cache add curl COPY build/libs/*-all.jar complete.jar CMD java ${JAVA_OPTS} -jar complete.jar Commit your change and watch the activity. 1 2 3 4 git add Dockerfile git commit -m fix Dockerfile git push jx get activity -f jx-micronaut-seed -w Once the Promote: staging is completed successfully, we should be able to test if the application is running! 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR You should see something like this: 1 2 3 4 5 6 7 html head title 503 Service Temporarily Unavailable / title / head body center h1 503 Service Temporarily Unavailable / h1 / center hr center nginx/1.15.8 / center / body / html Something is wrong...","title":"Confirm the application is building"},{"location":"buildpack/import/#find-out-what-is-wrong","text":"To find out what is wrong, lets check the pod status. 1 kubectl get pods -n jx-staging -l app = jx-jx-micronaut-seed We should see something as follows. 1 2 NAME READY STATUS RESTARTS AGE jx-jx-micronaut-seed-68f4bffb7b-mpb57 0 /1 CrashLoopBackOff 41 1h Let's describe the pod and see what is causing the CrashLoopBackOff . 1 kubectl describe pods -n jx-staging -l app = jx-jx-micronaut-seed If we look at the Events: section, we will see something like this: 1 2 3 4 5 6 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning Unhealthy 13m ( x1833 over 16h ) kubelet, gke-joostvdg-default-pool-6f512cf8-7l4l Readiness probe failed: HTTP probe failed with statuscode: 404 Normal Pulled 8m43s ( x240 over 16h ) kubelet, gke-joostvdg-default-pool-6f512cf8-7l4l Container image 10.23.250.118:5000/joostvdg/jx-micronaut-seed:0.0.3 already present on machine Warning BackOff 3m34s ( x2866 over 16h ) kubelet, gke-joostvdg-default-pool-6f512cf8-7l4l Back-off restarting failed container One of the things you can spot, is Readiness probe failed: HTTP probe failed with statuscode: 404 . Assuming our application is flawless - it passed it build test phase - it's likely that Kubernetes is looking at a non-existing endpoint for a health check.","title":"Find out what is wrong"},{"location":"buildpack/import/#fix-health-check","text":"As good as Jenkins X is, it isn't clairvoyant and cannot detect that our Micronaut application has a different health check endpoint. You might not know what the Micronaut framework gives you, but I can tell you. The health check endpoint is located at /health , not a bad place to put it. As the Gradle BuildPack is designed with Spring Boot in mind, it directs Kubernetes health check to /actuator/health . So we have to change this. Our application is packaged by Helm and the values for our Kubernetes Deployment - where the health check is configured - are located in /charts/jx-micronaut-seed/values.yaml . We have to change the value of probePath , from /actuator/health to /health . So please edit /charts/jx-micronaut-seed/values.yaml to reflect the change or use the below yq command. This should be the end result: 1 2 3 4 5 6 7 8 9 10 11 12 13 ... cpu : 500m memory : 512Mi requests : cpu : 400m memory : 512Mi probePath : /health livenessProbe : initialDelaySeconds : 60 periodSeconds : 10 successThreshold : 1 timeoutSeconds : 1 ... yq 1 yq w charts/jx-micronaut-seed/values.yaml --inplace probePath /health Now commit and push our change to fix our deployment! 1 2 3 4 git add charts/jx-micronaut-seed/values.yaml git commit -m fix health check endpoint git push jx get activity -f jx-micronaut-seed -w Once the applications is successfully promoted to staging, we can try again! 1 kubectl get pods -n jx-staging -l app = jx-jx-micronaut-seed Oh no, the application is still not running! 1 2 NAME READY STATUS RESTARTS AGE jx-jx-micronaut-seed-d5498679f-55b84 0 /1 Running 1 2m","title":"Fix Health Check"},{"location":"buildpack/import/#still-broken","text":"Let's describe the pod and see what is wrong this time. 1 kubectl describe pods -n jx-staging -l app = jx-jx-micronaut-seed 1 2 3 Warning Unhealthy 94s ( x2 over 3m14s ) kubelet, gke-joostvdg-default-pool-6f512cf8-41l4 Readiness probe failed: Get http://10.20.0.24:8080/health: dial tcp 10 .20.0.24:8080: connect: connection refused Warning Unhealthy 83s ( x2 over 3m3s ) kubelet, gke-joostvdg-default-pool-6f512cf8-41l4 Readiness probe failed: Get http://10.20.0.24:8080/health: net/http: request canceled ( Client.Timeout exceeded while awaiting headers ) Warning Unhealthy 54s ( x11 over 2m54s ) kubelet, gke-joostvdg-default-pool-6f512cf8-41l4 Readiness probe failed: HTTP probe failed with statuscode: 500 It seems our application is not getting into ready state: Readiness probe failed: HTTP probe failed with statuscode: 500 . Now this is a bit of cheat, because this application actually requires a connection with a Redis database in order to function. It can be build without it fine, and it will run fine, but Micronaut 's health check endpoint will incorporate the Redis connection into it's health status.","title":"Still broken"},{"location":"buildpack/import/#configure-redis-database","text":"This means we must make sure our application can talk to a Redis database!","title":"Configure Redis database"},{"location":"buildpack/import/#add-redis-dependency","text":"The easiest way to do this with Jenkins X , is to add a dependency to our Helm Chart . If our dependency exists as a health chart, that is. Just our luck, looking at Helm Stable Charts , there's a Redis chart we can add. To do so, we add a requirements.yaml to our Chart. Create a file charts/jx-micronaut-seed/requirements.yaml and fill in the below details. Raw YAML 1 2 3 4 5 dependencies : - alias : jx-micronaut-seed-redis name : redis repository : https://kubernetes-charts.storage.googleapis.com version : 6.1.0 CommandLine magic 1 2 3 4 5 6 echo dependencies: - alias: jx-micronaut-seed-redis name: redis repository: https://kubernetes-charts.storage.googleapis.com version: 6.1.0 | tee charts/jx-micronaut-seed/requirements.yaml","title":"Add Redis dependency"},{"location":"buildpack/import/#application-redis-config","text":"To be safe that whenever our application gets deployed via Helm it can find our database, we need to make sure the location it looks for is a variable. We can add this in three places, either in the application itself, in our values.yaml or in our deployment.yaml template. Our application will get deployed via Helm, which means the name it gets and the Redis dependency gets, will depend on the Helm release name. So in this particular case, it's best to add an environment variable to the deployment template. With a default value, that derives its value from the Helm release name. This makes the default install from Helm work and allows users of our Helm chart, to use a different Redis instance. To do so, we have to add the environment variable in charts/jx-micronaut-seed/templates/deployment.yaml . Add the below snippet to the spec.template.spec.containers[0] section between imagePullPolicy: {{ .Values.image.pullPolicy }} and ports: . Raw YAML 1 2 3 env : - name : REDIS_HOST value : {{ template fullname . }} -redis-master Command Line magic 1 2 3 4 5 cat charts/jx-micronaut-seed/templates/deployment.yaml | sed -e \\ s@env:@env:\\ - name: REDIS_HOST\\ value: {{ template fullname . }}-redis-master@g \\ | tee charts/jx-micronaut-seed/templates/deployment.yaml The end result should look like this: 1 2 3 4 5 6 7 8 9 spec : containers : - name : {{ .Chart.Name }} image : {{ .Values.image.repository }}:{{ .Values.image.tag }} imagePullPolicy : {{ .Values.image.pullPolicy }} env : - name : REDIS_HOST value : {{ template fullname . }} -redis-master ports :","title":"Application Redis config"},{"location":"buildpack/import/#redis-chart-config","text":"We need to do one last thing. The Redis chart by default generates a unique password on startup. This is nice and secure, but makes it difficult for our application to connect to it. Let's configure our Redis chart to not use a password for now. Add the below snippet at the bottom of charts/jx-micronaut-seed/values.yaml or use the command line magic for automation. Raw YAML 1 2 jx-micronaut-seed-redis : usePassword : false Command Line magic 1 2 3 echo jx-micronaut-seed-redis: usePassword: false | tee -a charts/jx-micronaut-seed/values.yaml","title":"Redis Chart config"},{"location":"buildpack/import/#commit-and-confirm","text":"Let's commit and push our changes and see if this was enough! 1 2 3 4 5 6 git add charts/jx-micronaut-seed/templates/deployment.yaml git add charts/jx-micronaut-seed/values.yaml git add charts/jx-micronaut-seed/requirements.yaml git commit -m add and configure redis dependency git push jx get activity -f jx-micronaut-seed -w","title":"Commit and confirm"},{"location":"buildpack/import/#confirm-it-works","text":"Once it succeeds, we can see if the applications does run now. 1 kubectl get pods -n jx-staging -l app = jx-jx-micronaut-seed It should now be running: 1 2 NAME READY STATUS RESTARTS AGE jx-jx-micronaut-seed-75ffd4fbc4-66sgr 1 /1 Running 0 9m Let's see if we can talk to it. curl 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) curl http:// $APP_ADDR /health httpie 1 2 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) http $APP_ADDR /health The answer is: 1 2 3 { status : UP } We've done it! Now lets use the Redis database in a wholefully inappropriate way. curl 1 2 3 4 5 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) curl --header Content-Type: application/json \\ --request POST --data { body : Something curl , sender : Joost } \\ http:// $APP_ADDR /message curl http:// $APP_ADDR /message httpie 1 2 3 APP_ADDR = $( kubectl get ing -n jx-staging jx-micronaut-seed -o jsonpath = {.spec.rules[0].host} ) http POST ${ APP_ADDR } /message body = Something httpie sender = Joost http ${ APP_ADDR } /message Now, in order to avoid having to this kind of ritual for every Micronaut based application, we should probably make a better starting point. Let's move on to create a BuildPack Info For more information on Jenkins X's jx import command, please consult the documentation at jenkins-x.io","title":"Confirm it works"},{"location":"k8s/","text":"Kubernetes Basics Pod Deployment Service Ingress Volume","title":"Basics"},{"location":"k8s/#kubernetes-basics","text":"","title":"Kubernetes Basics"},{"location":"k8s/#pod","text":"","title":"Pod"},{"location":"k8s/#deployment","text":"","title":"Deployment"},{"location":"k8s/#service","text":"","title":"Service"},{"location":"k8s/#ingress","text":"","title":"Ingress"},{"location":"k8s/#volume","text":"","title":"Volume"},{"location":"k8s/create-cluster/","text":"Install Kubernetes in Public Cloud GKE 1 CLUSTER_NAME =[ ... ] # Change to a random name (e.g., your user) 1 gcloud auth login 1 2 3 4 5 6 7 8 gcloud container clusters \\ create $CLUSTER_NAME \\ --region us-east1 \\ --machine-type n1-standard-1 \\ --enable-autoscaling \\ --num-nodes 1 \\ --max-nodes 3 \\ --min-nodes 1 1 2 3 4 kubectl create clusterrolebinding \\ cluster-admin-binding \\ --clusterrole cluster-admin \\ --user $( gcloud config get-value account ) 1 kubectl get nodes -o wide 1 2 3 4 gcloud container clusters \\ delete $CLUSTER_NAME \\ --region us-east1 \\ --quiet","title":"Create Cluster"},{"location":"k8s/create-cluster/#install-kubernetes-in-public-cloud","text":"","title":"Install Kubernetes in Public Cloud"},{"location":"k8s/create-cluster/#gke","text":"1 CLUSTER_NAME =[ ... ] # Change to a random name (e.g., your user) 1 gcloud auth login 1 2 3 4 5 6 7 8 gcloud container clusters \\ create $CLUSTER_NAME \\ --region us-east1 \\ --machine-type n1-standard-1 \\ --enable-autoscaling \\ --num-nodes 1 \\ --max-nodes 3 \\ --min-nodes 1 1 2 3 4 kubectl create clusterrolebinding \\ cluster-admin-binding \\ --clusterrole cluster-admin \\ --user $( gcloud config get-value account ) 1 kubectl get nodes -o wide 1 2 3 4 gcloud container clusters \\ delete $CLUSTER_NAME \\ --region us-east1 \\ --quiet","title":"GKE"},{"location":"k8s/helm/","text":"","title":"Helm"},{"location":"k8s/knative-build/","text":"","title":"Knative Build"},{"location":"k8s/tools/","text":"Kubernetes Tools Kuard Kuard is a small demo application to show your cluster works. Also exposes some info you might want to see. 1 2 kubectl run --restart = Never --image = gcr.io/kuar-demo/kuard-amd64:blue kuard kubectl port-forward kuard 8080 :8080 Open your browser to http://localhost:8080 . Stern Stern allows you to tail multiple pods on Kubernetes and multiple containers within the pod. Each result is color coded for quicker debugging. 1 brew install stern Usage Imagine a build in Jenkins using more than one container in the Pod. You want to tail the logs of all containers... you can with stern. 1 stern maven- Kube Capacity Kube Capacity is a simple CLI that provides an overview of the resource requests, limits, and utilization in a Kubernetes cluster. 1 2 brew tap robscott/tap brew install robscott/tap/kube-capacity 1 kube-capacity 1 2 3 4 NODE CPU REQUESTS CPU LIMITS MEMORY REQUESTS MEMORY LIMITS * 560m ( 28 % ) 130m ( 7 % ) 572Mi ( 9 % ) 770Mi ( 13 % ) example-node-1 220m ( 22 % ) 10m ( 1 % ) 192Mi ( 6 % ) 360Mi ( 12 % ) example-node-2 340m ( 34 % ) 120m ( 12 % ) 380Mi ( 13 % ) 410Mi ( 14 % ) 1 kube-capacity --pods 1 2 3 4 5 6 7 8 9 10 NODE NAMESPACE POD CPU REQUESTS CPU LIMITS MEMORY REQUESTS MEMORY LIMITS * * * 560m ( 28 % ) 780m ( 38 % ) 572Mi ( 9 % ) 770Mi ( 13 % ) example-node-1 * * 220m ( 22 % ) 320m ( 32 % ) 192Mi ( 6 % ) 360Mi ( 12 % ) example-node-1 kube-system metrics-server-lwc6z 100m ( 10 % ) 200m ( 20 % ) 100Mi ( 3 % ) 200Mi ( 7 % ) example-node-1 kube-system coredns-7b5bcb98f8 120m ( 12 % ) 120m ( 12 % ) 92Mi ( 3 % ) 160Mi ( 5 % ) example-node-2 * * 340m ( 34 % ) 460m ( 46 % ) 380Mi ( 13 % ) 410Mi ( 14 % ) example-node-2 kube-system kube-proxy-3ki7 200m ( 20 % ) 280m ( 28 % ) 210Mi ( 7 % ) 210Mi ( 7 % ) example-node-2 tiller tiller-deploy 140m ( 14 % ) 180m ( 18 % ) 170Mi ( 5 % ) 200Mi ( 7 % ) 1 kube-capacity --util 1 2 3 4 NODE CPU REQUESTS CPU LIMITS CPU UTIL MEMORY REQUESTS MEMORY LIMITS MEMORY UTIL * 560m ( 28 % ) 130m ( 7 % ) 40m ( 2 % ) 572Mi ( 9 % ) 770Mi ( 13 % ) 470Mi ( 8 % ) example-node-1 220m ( 22 % ) 10m ( 1 % ) 10m ( 1 % ) 192Mi ( 6 % ) 360Mi ( 12 % ) 210Mi ( 7 % ) example-node-2 340m ( 34 % ) 120m ( 12 % ) 30m ( 3 % ) 380Mi ( 13 % ) 410Mi ( 14 % ) 260Mi ( 9 % ) 1 kube-capacity --pods --util Velero Velero RBAC Lookup RBAC Lookup Install bash 1 brew install reactiveops/tap/rbac-lookup Krew 1 kubectl krew install rbac-lookup Lookup user 1 rbac-lookup jvandergriendt -owide Lookup GKE user 1 rbac-lookup jvandergriendt --gke K9S K9S is a tool that gives you a console UI on your kubernetes cluster/namespace. Install 1 brew tap derailed/k9s brew install k9s Use By default is looks at a single namespace, and allows you to view elements of the pods running. 1 k9s -n cje Dive A tool for exploring a docker image, layer contents, and discovering ways to shrink your Docker image size. Dive is a tool for analyzing Docker images. Install Debian based 1 2 wget https://github.com/wagoodman/dive/releases/download/v0.7.1/dive_0.7.1_linux_amd64.deb sudo apt install ./dive_0.7.1_linux_amd64.deb RHEL based 1 2 curl -OL https://github.com/wagoodman/dive/releases/download/v0.7.1/dive_0.7.1_linux_amd64.rpm rpm -i dive_0.7.1_linux_amd64.rpm Homebrew 1 2 brew tap wagoodman/dive brew install dive Windows 1 go get github.com/wagoodman/dive Use Existing image 1 dive your-image-tag To be build image 1 dive build -t some-tag . For CI builds 1 CI = true dive your-image Kiali https://www.kiali.io/ Telepresence https://www.telepresence.io/","title":"Tools"},{"location":"k8s/tools/#kubernetes-tools","text":"","title":"Kubernetes Tools"},{"location":"k8s/tools/#kuard","text":"Kuard is a small demo application to show your cluster works. Also exposes some info you might want to see. 1 2 kubectl run --restart = Never --image = gcr.io/kuar-demo/kuard-amd64:blue kuard kubectl port-forward kuard 8080 :8080 Open your browser to http://localhost:8080 .","title":"Kuard"},{"location":"k8s/tools/#stern","text":"Stern allows you to tail multiple pods on Kubernetes and multiple containers within the pod. Each result is color coded for quicker debugging. 1 brew install stern","title":"Stern"},{"location":"k8s/tools/#usage","text":"Imagine a build in Jenkins using more than one container in the Pod. You want to tail the logs of all containers... you can with stern. 1 stern maven-","title":"Usage"},{"location":"k8s/tools/#kube-capacity","text":"Kube Capacity is a simple CLI that provides an overview of the resource requests, limits, and utilization in a Kubernetes cluster. 1 2 brew tap robscott/tap brew install robscott/tap/kube-capacity 1 kube-capacity 1 2 3 4 NODE CPU REQUESTS CPU LIMITS MEMORY REQUESTS MEMORY LIMITS * 560m ( 28 % ) 130m ( 7 % ) 572Mi ( 9 % ) 770Mi ( 13 % ) example-node-1 220m ( 22 % ) 10m ( 1 % ) 192Mi ( 6 % ) 360Mi ( 12 % ) example-node-2 340m ( 34 % ) 120m ( 12 % ) 380Mi ( 13 % ) 410Mi ( 14 % ) 1 kube-capacity --pods 1 2 3 4 5 6 7 8 9 10 NODE NAMESPACE POD CPU REQUESTS CPU LIMITS MEMORY REQUESTS MEMORY LIMITS * * * 560m ( 28 % ) 780m ( 38 % ) 572Mi ( 9 % ) 770Mi ( 13 % ) example-node-1 * * 220m ( 22 % ) 320m ( 32 % ) 192Mi ( 6 % ) 360Mi ( 12 % ) example-node-1 kube-system metrics-server-lwc6z 100m ( 10 % ) 200m ( 20 % ) 100Mi ( 3 % ) 200Mi ( 7 % ) example-node-1 kube-system coredns-7b5bcb98f8 120m ( 12 % ) 120m ( 12 % ) 92Mi ( 3 % ) 160Mi ( 5 % ) example-node-2 * * 340m ( 34 % ) 460m ( 46 % ) 380Mi ( 13 % ) 410Mi ( 14 % ) example-node-2 kube-system kube-proxy-3ki7 200m ( 20 % ) 280m ( 28 % ) 210Mi ( 7 % ) 210Mi ( 7 % ) example-node-2 tiller tiller-deploy 140m ( 14 % ) 180m ( 18 % ) 170Mi ( 5 % ) 200Mi ( 7 % ) 1 kube-capacity --util 1 2 3 4 NODE CPU REQUESTS CPU LIMITS CPU UTIL MEMORY REQUESTS MEMORY LIMITS MEMORY UTIL * 560m ( 28 % ) 130m ( 7 % ) 40m ( 2 % ) 572Mi ( 9 % ) 770Mi ( 13 % ) 470Mi ( 8 % ) example-node-1 220m ( 22 % ) 10m ( 1 % ) 10m ( 1 % ) 192Mi ( 6 % ) 360Mi ( 12 % ) 210Mi ( 7 % ) example-node-2 340m ( 34 % ) 120m ( 12 % ) 30m ( 3 % ) 380Mi ( 13 % ) 410Mi ( 14 % ) 260Mi ( 9 % ) 1 kube-capacity --pods --util","title":"Kube Capacity"},{"location":"k8s/tools/#velero","text":"Velero","title":"Velero"},{"location":"k8s/tools/#rbac-lookup","text":"RBAC Lookup","title":"RBAC Lookup"},{"location":"k8s/tools/#install","text":"bash 1 brew install reactiveops/tap/rbac-lookup Krew 1 kubectl krew install rbac-lookup","title":"Install"},{"location":"k8s/tools/#lookup-user","text":"1 rbac-lookup jvandergriendt -owide","title":"Lookup user"},{"location":"k8s/tools/#lookup-gke-user","text":"1 rbac-lookup jvandergriendt --gke","title":"Lookup GKE user"},{"location":"k8s/tools/#k9s","text":"K9S is a tool that gives you a console UI on your kubernetes cluster/namespace.","title":"K9S"},{"location":"k8s/tools/#install_1","text":"1 brew tap derailed/k9s brew install k9s","title":"Install"},{"location":"k8s/tools/#use","text":"By default is looks at a single namespace, and allows you to view elements of the pods running. 1 k9s -n cje","title":"Use"},{"location":"k8s/tools/#dive","text":"A tool for exploring a docker image, layer contents, and discovering ways to shrink your Docker image size. Dive is a tool for analyzing Docker images.","title":"Dive"},{"location":"k8s/tools/#install_2","text":"Debian based 1 2 wget https://github.com/wagoodman/dive/releases/download/v0.7.1/dive_0.7.1_linux_amd64.deb sudo apt install ./dive_0.7.1_linux_amd64.deb RHEL based 1 2 curl -OL https://github.com/wagoodman/dive/releases/download/v0.7.1/dive_0.7.1_linux_amd64.rpm rpm -i dive_0.7.1_linux_amd64.rpm Homebrew 1 2 brew tap wagoodman/dive brew install dive Windows 1 go get github.com/wagoodman/dive","title":"Install"},{"location":"k8s/tools/#use_1","text":"Existing image 1 dive your-image-tag To be build image 1 dive build -t some-tag . For CI builds 1 CI = true dive your-image","title":"Use"},{"location":"k8s/tools/#kiali","text":"https://www.kiali.io/","title":"Kiali"},{"location":"k8s/tools/#telepresence","text":"https://www.telepresence.io/","title":"Telepresence"},{"location":"other/alt-git-repo/","text":"Alternative Git Repository","title":"Alt Git Repo"},{"location":"other/alt-git-repo/#alternative-git-repository","text":"","title":"Alternative Git Repository"},{"location":"other/cluster-validation/","text":"Cluster Validation You can read this article from Viktor Farcic on how to confirm if your cluster is compliant with Jenkins X's requirements. Jenkins X has a binary, called jx , which includes some facilities from the Sonobuoy SDK to provide some validation capabilities. Run compliance check To run the compliance check, just use the jx command below. 1 jx compliance run Warning The compliance check will run for about one hour! Check Compliance run status 1 jx compliance status Check Compliance run logs 1 jx compliance logs -f See Compliance run results 1 jx compliance results Cleanup Once you're done with the compliance run, you can clean up any resources it created for the run. 1 jx compliance delete","title":"Cluster Validation"},{"location":"other/cluster-validation/#cluster-validation","text":"You can read this article from Viktor Farcic on how to confirm if your cluster is compliant with Jenkins X's requirements. Jenkins X has a binary, called jx , which includes some facilities from the Sonobuoy SDK to provide some validation capabilities.","title":"Cluster Validation"},{"location":"other/cluster-validation/#run-compliance-check","text":"To run the compliance check, just use the jx command below. 1 jx compliance run Warning The compliance check will run for about one hour!","title":"Run compliance check"},{"location":"other/cluster-validation/#check-compliance-run-status","text":"1 jx compliance status","title":"Check Compliance run status"},{"location":"other/cluster-validation/#check-compliance-run-logs","text":"1 jx compliance logs -f","title":"Check Compliance run logs"},{"location":"other/cluster-validation/#see-compliance-run-results","text":"1 jx compliance results","title":"See Compliance run results"},{"location":"other/cluster-validation/#cleanup","text":"Once you're done with the compliance run, you can clean up any resources it created for the run. 1 jx compliance delete","title":"Cleanup"},{"location":"other/custom-domain/","text":"Custom Domain","title":"Custom Domain"},{"location":"other/custom-domain/#custom-domain","text":"","title":"Custom Domain"},{"location":"other/issue-trackers/","text":"Issue Trackers Jenkins X can work with issue trackers such as GitHub issues and Jira. By default, Jenkins X will use GitHub for projects and issues. So if you haven't specified anything for either Git provider or Issue tracker, it will use GitHub for issues. GitHub 1 jx create issue -t lets make things more awesome 1 jx get issues Jira In order to configure Jenkins X to use Jira as issue tracker, you have to do three steps. create a tracker configuration jx create tracker server ${trackerName} https://mycompany.atlassian.net/ create a tracker login jx create tracker token -n ${trackerName} myEmailAddress configure your Jenkins X managed project to use this issue tracker instead jx edit config -k issues Info A file called jenkins-x.yml will be modified in your project source code which should be added to your git repository.","title":"Issue Trackers"},{"location":"other/issue-trackers/#issue-trackers","text":"Jenkins X can work with issue trackers such as GitHub issues and Jira. By default, Jenkins X will use GitHub for projects and issues. So if you haven't specified anything for either Git provider or Issue tracker, it will use GitHub for issues.","title":"Issue Trackers"},{"location":"other/issue-trackers/#github","text":"1 jx create issue -t lets make things more awesome 1 jx get issues","title":"GitHub"},{"location":"other/issue-trackers/#jira","text":"In order to configure Jenkins X to use Jira as issue tracker, you have to do three steps. create a tracker configuration jx create tracker server ${trackerName} https://mycompany.atlassian.net/ create a tracker login jx create tracker token -n ${trackerName} myEmailAddress configure your Jenkins X managed project to use this issue tracker instead jx edit config -k issues Info A file called jenkins-x.yml will be modified in your project source code which should be added to your git repository.","title":"Jira"},{"location":"other/security/","text":"Security features Secure Coding Jenkins X has direct support for some security analysis . Anchore image scanning The Anchore Engine is used to provide image security, by examining contents of containers either in pull request/review state, or on running containers. This was introduced in this blog post . Here is a video demonstrating it live. 1 jx create addon anchore To see if it found any problems in a specific environment: 1 jx get cve --environment = staging OWASP ZAP ZAP or Zed Attack Proxy allows you to scan the public surface of your application for any known vulnerability. 1 jx create addon owasp-zap","title":"Security"},{"location":"other/security/#security-features","text":"","title":"Security features"},{"location":"other/security/#secure-coding","text":"Jenkins X has direct support for some security analysis .","title":"Secure Coding"},{"location":"other/security/#anchore-image-scanning","text":"The Anchore Engine is used to provide image security, by examining contents of containers either in pull request/review state, or on running containers. This was introduced in this blog post . Here is a video demonstrating it live. 1 jx create addon anchore To see if it found any problems in a specific environment: 1 jx get cve --environment = staging","title":"Anchore image scanning"},{"location":"other/security/#owasp-zap","text":"ZAP or Zed Attack Proxy allows you to scan the public surface of your application for any known vulnerability. 1 jx create addon owasp-zap","title":"OWASP ZAP"},{"location":"serverless/","text":"Serverless JX","title":"Intro"},{"location":"serverless/#serverless-jx","text":"","title":"Serverless JX"},{"location":"tips/","text":"Tips Tricks https://github.com/jenkinsci/kubernetes-credentials-provider-plugin volume storage with Heptio's Valerio debugging: https://jenkins-x.io/contribute/development/#debugging --gitops mode have to check this jx upgrade platform knative authentication --git-username --org are complimentary, --organisations is unrelated username = the user for the repo's (apps env) org = the organization for the repo's (apps env) e.g.: --git-username joostvdg --org demomon --organisations is used to query GitHub for Quickstarts (no need to specify unless you have alternatives) Jenkins configurations do not persist you can specify them in a ConfigMap though https://github.com/jenkins-x/charts/blob/jenkins/stable/jenkins/templates/config.yaml#L8 credentials used for config can be found here: ~/.jx/jenkinsAuth.yam PodTemplates (static Jenkins) are from the Jenkins Kubernetes Plugin cleanup GKE jx gc gke you can create separate teams with --no-tiller even if the installation was done with Tiller jx init to \"fix\" a outdated ~/.jx folder https://jenkins-x.io/commands/jx_step_credential/ don't do mono repo's why? - https://medium.com/@mattklein123/monorepos-please-dont-e9a279be011b but if you do, https://fuchsia.googlesource.com/jiri/ using a different git provider --git-provider-url .... --git-provider-kind bitbucketserver --git-username foo --git-api-token whatever https://jenkins-x.io/developing/git/#using-a-different-git-provider-for-environments jx start pipeline to manually trigger a pipeline (I assume static Jenkins only) enable GCS for chartmuseum backend https://github.com/jenkins-x/cloud-environments/blob/master/env-jx-infra/myvalues.yaml#L10-L17 jx wraps kubectx tool, so you can use jx ns namespace to change your context to a different namespace faq for diagnosing exposecontroller issues: https://jenkins-x.io/faq/issues/#how-can-i-diagnose-exposecontroller-issues controller is used to generate ingress resources https://github.com/lvlstudio/jenkins-x-builders/tree/master/builder-nodejs-mysql https://github.com/jenkins-x/jx/issues/2550 https://github.com/jenkins-x/jenkins-x-platform/issues/4768 Tillerless: https://jenkins-x.io/news/helm-without-tiller/ difference between jx create quickstart and selecting spring vs. jx create spring jx create spring is an interactive wizard that uses the spring initialiser https://start.spring.io/ jx create quickstart uses a configurable github org to list available existing quickstarts i.e. https://github.com/jenkins-x-quickstarts (edited) multi-cluster support: https://github.com/jenkins-x-charts/environment-controller https://github.com/jenkins-x/jx/issues/479 jx create user ? https://jenkins-x.io/commands/jx_create_jenkins_token/ for problems with wild card certificates doing only one segment (i.e., *.example.com instead of *.*.example.com ) no - we can tweak that. It\u2019s easiest with wildcard - then any exposed service at svc.ns.domain just works - but you could register each namespace in DNS we\u2019ve not exposed that property to the jx install CLI yet - but you could try kubectl edit cm ingress-config urltemplate: {{.Service}}-{{.Namespace}}.{{.Domain}} and then jx upgrade ingress doesn't seem to work yet? (customization gets reverted) alternative, add dns entries to the ingress resources https://jenkins-x.io/getting-started/install-on-cluster/#installing-jenkins-x-on-premise Helm tips tricks for changing secrets https://github.com/helm/helm/blob/master/docs/charts_tips_and_tricks.md#user-content-automatically-roll-deployments-when-configmaps-or-secrets-change how to run integration tests I've answered this in a previous thread. Basically you use the helm chart (which includes the service dependencies as requirements). You create a preview but set the replicaCount for your service to 0 (that way, just the requirements are started). Then just run your tests against the requirements and delete the preview afterwards. Search the channel history for my messages and replicaCount. You should find it. https://jenkins-x.io/faq/develop/#how-do-i-add-other-services-into-a-preview managing static jenkins config has some issues https://github.com/jenkins-x/jx/issues/2991 https://github.com/jenkins-x/jx-docs/issues/1039 https://github.com/helm/charts/pull/9296/files we\u2019re super close from recommending folks use jx create cluster ... --vault --gitops which uses a git repository to store all the configuration changes + versions of stuff - and uses Vault to store all secrets we just merged the last few fixes so it should work for static jenkins servers with the latest jx binary - feb 7 Info It is Ready: jx create cluster gke --vault --gitops --no-tiller Multiple Micro-services if 1 microservice was 1 helm chart with a few different containers for example; you may have a few repos that just make binaries/docker images - then 1 repo which contains the helm chart of the microservice - you can also easily combine microservices together into an uber helm chart - James Strachan we prefer to use multiple repositories so that things are more microservice based. The problem with monorepos is everything gets released on every change; with separate repos its easier to manage change etc to handle changing versions of things across repositories we use updatebot ourselves to do \u2018CI/CD of dependencies\u2019 - we kinda think of it as promotion of dependencies like we promote microservices into environments - its PRs generated as part of the release process the main decision to make really is, , if you have, say, 3 microservices that are fairly tightly coupled; do you combine 3 versions of them all into 1 chart and then release that 1 chart when its all tested together; or do you release the 3 things totally independently - it depeends on coupling and team structure really you can switch from one to the other at any time really https://github.com/jenkins-x/updatebot 1 2 3 4 5 6 7 8 9 10 11 12 # Setup: $ jx create cluster gke -n team1 --default-environment-prefix team1 $ jx create quickstart -p app1 $ jx create quickstart -p app2 $ jx create quickstart -p app3 # The 5 repos: environment-team1-staging environment-team1-production app1 app2 app3","title":"Tips"},{"location":"tips/#tips-tricks","text":"https://github.com/jenkinsci/kubernetes-credentials-provider-plugin volume storage with Heptio's Valerio debugging: https://jenkins-x.io/contribute/development/#debugging --gitops mode have to check this jx upgrade platform knative authentication --git-username --org are complimentary, --organisations is unrelated username = the user for the repo's (apps env) org = the organization for the repo's (apps env) e.g.: --git-username joostvdg --org demomon --organisations is used to query GitHub for Quickstarts (no need to specify unless you have alternatives) Jenkins configurations do not persist you can specify them in a ConfigMap though https://github.com/jenkins-x/charts/blob/jenkins/stable/jenkins/templates/config.yaml#L8 credentials used for config can be found here: ~/.jx/jenkinsAuth.yam PodTemplates (static Jenkins) are from the Jenkins Kubernetes Plugin cleanup GKE jx gc gke you can create separate teams with --no-tiller even if the installation was done with Tiller jx init to \"fix\" a outdated ~/.jx folder https://jenkins-x.io/commands/jx_step_credential/ don't do mono repo's why? - https://medium.com/@mattklein123/monorepos-please-dont-e9a279be011b but if you do, https://fuchsia.googlesource.com/jiri/ using a different git provider --git-provider-url .... --git-provider-kind bitbucketserver --git-username foo --git-api-token whatever https://jenkins-x.io/developing/git/#using-a-different-git-provider-for-environments jx start pipeline to manually trigger a pipeline (I assume static Jenkins only) enable GCS for chartmuseum backend https://github.com/jenkins-x/cloud-environments/blob/master/env-jx-infra/myvalues.yaml#L10-L17 jx wraps kubectx tool, so you can use jx ns namespace to change your context to a different namespace faq for diagnosing exposecontroller issues: https://jenkins-x.io/faq/issues/#how-can-i-diagnose-exposecontroller-issues controller is used to generate ingress resources https://github.com/lvlstudio/jenkins-x-builders/tree/master/builder-nodejs-mysql https://github.com/jenkins-x/jx/issues/2550 https://github.com/jenkins-x/jenkins-x-platform/issues/4768 Tillerless: https://jenkins-x.io/news/helm-without-tiller/ difference between jx create quickstart and selecting spring vs. jx create spring jx create spring is an interactive wizard that uses the spring initialiser https://start.spring.io/ jx create quickstart uses a configurable github org to list available existing quickstarts i.e. https://github.com/jenkins-x-quickstarts (edited) multi-cluster support: https://github.com/jenkins-x-charts/environment-controller https://github.com/jenkins-x/jx/issues/479 jx create user ? https://jenkins-x.io/commands/jx_create_jenkins_token/ for problems with wild card certificates doing only one segment (i.e., *.example.com instead of *.*.example.com ) no - we can tweak that. It\u2019s easiest with wildcard - then any exposed service at svc.ns.domain just works - but you could register each namespace in DNS we\u2019ve not exposed that property to the jx install CLI yet - but you could try kubectl edit cm ingress-config urltemplate: {{.Service}}-{{.Namespace}}.{{.Domain}} and then jx upgrade ingress doesn't seem to work yet? (customization gets reverted) alternative, add dns entries to the ingress resources https://jenkins-x.io/getting-started/install-on-cluster/#installing-jenkins-x-on-premise Helm tips tricks for changing secrets https://github.com/helm/helm/blob/master/docs/charts_tips_and_tricks.md#user-content-automatically-roll-deployments-when-configmaps-or-secrets-change how to run integration tests I've answered this in a previous thread. Basically you use the helm chart (which includes the service dependencies as requirements). You create a preview but set the replicaCount for your service to 0 (that way, just the requirements are started). Then just run your tests against the requirements and delete the preview afterwards. Search the channel history for my messages and replicaCount. You should find it. https://jenkins-x.io/faq/develop/#how-do-i-add-other-services-into-a-preview managing static jenkins config has some issues https://github.com/jenkins-x/jx/issues/2991 https://github.com/jenkins-x/jx-docs/issues/1039 https://github.com/helm/charts/pull/9296/files we\u2019re super close from recommending folks use jx create cluster ... --vault --gitops which uses a git repository to store all the configuration changes + versions of stuff - and uses Vault to store all secrets we just merged the last few fixes so it should work for static jenkins servers with the latest jx binary - feb 7 Info It is Ready: jx create cluster gke --vault --gitops --no-tiller","title":"Tips &amp; Tricks"},{"location":"tips/#multiple-micro-services","text":"if 1 microservice was 1 helm chart with a few different containers for example; you may have a few repos that just make binaries/docker images - then 1 repo which contains the helm chart of the microservice - you can also easily combine microservices together into an uber helm chart - James Strachan we prefer to use multiple repositories so that things are more microservice based. The problem with monorepos is everything gets released on every change; with separate repos its easier to manage change etc to handle changing versions of things across repositories we use updatebot ourselves to do \u2018CI/CD of dependencies\u2019 - we kinda think of it as promotion of dependencies like we promote microservices into environments - its PRs generated as part of the release process the main decision to make really is, , if you have, say, 3 microservices that are fairly tightly coupled; do you combine 3 versions of them all into 1 chart and then release that 1 chart when its all tested together; or do you release the 3 things totally independently - it depeends on coupling and team structure really you can switch from one to the other at any time really https://github.com/jenkins-x/updatebot 1 2 3 4 5 6 7 8 9 10 11 12 # Setup: $ jx create cluster gke -n team1 --default-environment-prefix team1 $ jx create quickstart -p app1 $ jx create quickstart -p app2 $ jx create quickstart -p app3 # The 5 repos: environment-team1-staging environment-team1-production app1 app2 app3","title":"Multiple Micro-services"},{"location":"tips/commands/","text":"Useful Commands JX Shell Create a sub shell so that changes to the Kubernetes context, namespace or environment remain local to the shell 1 2 # create a new shell using a specific named context jx shell prod-cluster JX Prompt Generate the command line prompt for the current team and environment current 1 2 # Generate the current prompt jx prompt bash 1 2 # Enable the prompt for bash PS1 = [\\u@\\h \\W \\$(jx prompt)]\\$ zsh 1 2 # Enable the prompt for zsh PROMPT = $(jx prompt) $PROMPT JX Helm As of this writing, April 2019, Tiller is no longer installed by default. This means Helm cannot find it's releases. To interact with Helm as you're used to, use jx step helm instead. 1 jx step helm list For more details, read the docs .","title":"Command Overview"},{"location":"tips/commands/#useful-commands","text":"","title":"Useful Commands"},{"location":"tips/commands/#jx-shell","text":"Create a sub shell so that changes to the Kubernetes context, namespace or environment remain local to the shell 1 2 # create a new shell using a specific named context jx shell prod-cluster","title":"JX Shell"},{"location":"tips/commands/#jx-prompt","text":"Generate the command line prompt for the current team and environment current 1 2 # Generate the current prompt jx prompt bash 1 2 # Enable the prompt for bash PS1 = [\\u@\\h \\W \\$(jx prompt)]\\$ zsh 1 2 # Enable the prompt for zsh PROMPT = $(jx prompt) $PROMPT","title":"JX Prompt"},{"location":"tips/commands/#jx-helm","text":"As of this writing, April 2019, Tiller is no longer installed by default. This means Helm cannot find it's releases. To interact with Helm as you're used to, use jx step helm instead. 1 jx step helm list For more details, read the docs .","title":"JX Helm"},{"location":"tips/gitops/","text":"Jenkins X - GitOps flag","title":"GitOps"},{"location":"tips/gitops/#jenkins-x-gitops-flag","text":"","title":"Jenkins X  - GitOps flag"},{"location":"tips/vault/","text":"Vault addon","title":"Vault"},{"location":"tips/vault/#vault-addon","text":"","title":"Vault addon"},{"location":"xfiles/","text":"XFiles Demo","title":"Overview"},{"location":"xfiles/#xfiles-demo","text":"","title":"XFiles Demo"},{"location":"xfiles/integration/","text":"XFiles - Integration","title":"Integration"},{"location":"xfiles/integration/#xfiles-integration","text":"","title":"XFiles - Integration"},{"location":"xfiles/mulder/","text":"XFiles - Mulder","title":"Mulder"},{"location":"xfiles/mulder/#xfiles-mulder","text":"","title":"XFiles - Mulder"},{"location":"xfiles/scully/","text":"XFiles - Scully","title":"Scully"},{"location":"xfiles/scully/#xfiles-scully","text":"","title":"XFiles - Scully"}]}